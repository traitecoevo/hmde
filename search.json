[{"path":[]},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"circumstances number observations available per individual limited, average growth rates time may plausible model fit. particular, individuals two size observations, best can done single estimate growth rate based interval. model behaves constant growth, can think average rate change across observation period given f(Y(t),Œ≤)=Œ≤\\begin{equation}\\tag{3}\\label{eqn_3_const} f(Y(t), \\beta) = \\beta \\end{equation} Œ≤\\beta average growth rate. constant growth model corresponds linear sizes time, equivalent linear mixed model size, individual effect fit multiple individuals.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"load-dependencies","dir":"Articles","previous_headings":"Overview","what":"Load dependencies","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"","code":"# remotes::install_github(\"traitecoevo/hmde\") # install.packages(c(\"dplyr\", \"ggplot2\"))  library(hmde) library(dplyr) library(ggplot2)"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"priors","dir":"Articles","previous_headings":"Overview","what":"Priors","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"default priors constant top-level parameters single individual model Œ≤‚àºlogùí©(0,2),\\beta\\sim \\log\\mathcal{N}(0, 2),0<œÉe‚àºCauchy(0,2).0 <\\sigma_e \\sim Cauchy(0, 2). multi-individual model prior structure default parameters ŒºŒ≤‚àºùí©(0,2),\\mu_{\\beta} \\sim \\mathcal{N}(0, 2),0<œÉŒ≤‚àºCauchy(0,2),0 < \\sigma_{\\beta} \\sim Cauchy(0, 2),0<œÉe‚àºCauchy(0,2).0 < \\sigma_{e} \\sim Cauchy(0, 2). change prior parameter values (distributions fixed) optional arguments can passed hmde_assign_data names corresponding prior_pars argument associated parameter output hmde_models(). example following want change prior Œ≤\\beta (ind_beta) individual model: mean passed log-normal distribution mean underlying normal distribution, want pass value based raw observations need log-transform first. Let‚Äôs simulate data visualise constant growth function.","code":"hmde_model(\"constant_single_ind\") #> [1] \"Model: constant_single_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $prior_pars_ind_beta #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_single_ind\" #prior_pars_ind_beta is the argument name for the prior parameters"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"simulate-data","dir":"Articles","previous_headings":"Overview","what":"Simulate data","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"","code":"beta <- 2 #Annual growth rate y_0 <- 1 #Starting size time <- 0:20  sizes_over_time <- tibble(Y_t = 1 + beta*time, #Linear sizes over time                           t = time)  sizes_over_time #> # A tibble: 21 √ó 2 #>      Y_t     t #>    <dbl> <int> #>  1     1     0 #>  2     3     1 #>  3     5     2 #>  4     7     3 #>  5     9     4 #>  6    11     5 #>  7    13     6 #>  8    15     7 #>  9    17     8 #> 10    19     9 #> # ‚Ñπ 11 more rows"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"visualise-data","dir":"Articles","previous_headings":"Overview","what":"Visualise data","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"plots demonstrate constant growth function relates sizes time single individual. Feel free play around parameter settings (beta, y_0) see plot changes.  key take-away function plot (left) relationship think ‚Äúreasonable growth model‚Äù. don‚Äôt expect constant growth rates realistic, best represent average rate change period. complex models may realistic, case study interested different mechanisms size dependence, use environmental covariates example.","code":"#Plot of growth function ggplot() +   geom_function(fun = hmde_model_des(\"constant_single_ind\"), # Visualising the growth function                 args = list(pars = list(beta)),                 colour = \"green4\", linewidth=1,                 xlim = c(y_0, max(sizes_over_time))) +    xlim(y_0, max(sizes_over_time$Y_t)) + # Creating the x axis   ylim(0, beta*2) + # Creating the y axis   labs(x = \"Y(t)\", y = \"f\", title = \"Constant growth\") + # Axe labels and plot title   theme_classic() + # Theme for the plot   theme(axis.text=element_text(size=16), # Plot customising         axis.title=element_text(size=18,face=\"bold\"))   #Sizes over time ggplot(data = sizes_over_time, aes(x=t, y = Y_t)) +    geom_line(colour=\"green4\", linewidth=1) + # Line graph of sizes_over_time   xlim(0, max(sizes_over_time$t)) +   ylim(0, max(sizes_over_time$Y_t)*1.05) +   labs(x = \"Time\", y = \"Y(t)\", title = \"Constant growth\") +   theme_classic() +   theme(axis.text=element_text(size=16),         axis.title=element_text(size=18,face=\"bold\"))"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"sustain-trout-data","dir":"Articles","previous_headings":"","what":"SUSTAIN trout data","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"example data constant model comes Moe et al. (2020), publicly available dataset mark-recapture data Salmo trutta Norway. time observations controlled, number observations per individual. result data consists primarily individuals two observations size, constituting single observation growth limits growth functions can fit individuals single parameter model best can fit two sizes. constant growth function Equation appropriate functions hmde, can interpret single growth interval estimate average growth rate gets fit Œ≤\\beta. order best reflect survey data took stratified sample individuals grouped number available observations. 25 fish two observations, 15 three, 10 four, total sample size 50. data included hmde","code":"Trout_Size_Data #> # A tibble: 135 √ó 4 #>    ind_id  time y_obs obs_index #>     <dbl> <dbl> <dbl>     <dbl> #>  1      1  0       52         1 #>  2      1  1.91    60         2 #>  3      1  4.02    70         3 #>  4      1  6.04    80         4 #>  5      2  0       80         1 #>  6      2  1.90    85         2 #>  7      2  3.94    93         3 #>  8      2  5.96    94         4 #>  9      3  0       52         1 #> 10      3  2.03    65         2 #> # ‚Ñπ 125 more rows"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"transform-data","dir":"Articles","previous_headings":"SUSTAIN trout data","what":"Transform data","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"initial exploration look distribution observed sizes, growth behaviour, observation intervals. First transform data extract growth increment observation interval information, plot .","code":"Trout_Size_Data_transformed <- Trout_Size_Data %>%   group_by(ind_id) %>%   mutate(     delta_y_obs = y_obs - lag(y_obs),     obs_interval = time - lag(time),     obs_growth_rate = delta_y_obs/obs_interval   ) %>%   ungroup()  Trout_Size_Data_transformed #> # A tibble: 135 √ó 7 #>    ind_id  time y_obs obs_index delta_y_obs obs_interval obs_growth_rate #>     <dbl> <dbl> <dbl>     <dbl>       <dbl>        <dbl>           <dbl> #>  1      1  0       52         1          NA        NA             NA     #>  2      1  1.91    60         2           8         1.91           4.18  #>  3      1  4.02    70         3          10         2.11           4.75  #>  4      1  6.04    80         4          10         2.02           4.96  #>  5      2  0       80         1          NA        NA             NA     #>  6      2  1.90    85         2           5         1.90           2.64  #>  7      2  3.94    93         3           8         2.04           3.92  #>  8      2  5.96    94         4           1         2.03           0.494 #>  9      3  0       52         1          NA        NA             NA     #> 10      3  2.03    65         2          13         2.03           6.42  #> # ‚Ñπ 125 more rows"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"visualise-raw-data","dir":"Articles","previous_headings":"SUSTAIN trout data","what":"Visualise raw data","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"Let‚Äôs create histograms investigate distribution size, growth interval growth increments.  growth histograms show ‚Äôs number negative growth increments, reasonably extreme, combined short observation periods get extreme estimates growth rates. can investigate needed. constant growth model assumes non-negative growth uses log-normal distribution Œ≤\\beta, eliminate increments estimated sizes. consider eliminating negative growth biologically reasonable don‚Äôt expect length fish decrease time, even mass width might.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"fit-model-using-hmde","dir":"Articles","previous_headings":"SUSTAIN trout data","what":"Fit model using {hmde}","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"Now actually fit model extract estimates. can see data structures needed constant growth model following methods: name represents element list gets passed model: - n_obs integer number observations yijy_{ij} - n_ind integer number individuals - y_obs vector yijy_{ij} observations length n_obs - obs_index vector containing integer jj index individual ii, counts observation yijy_{ij} sequence - time vector determines observation happened relative first observation individual. first observation time 0 - ind_id vector length y_obs tracks individual observation comes - prior_pars_pop_log_beta_mean vector prior parameters log-beta mean hyper-parameter - prior_pars_pop_log_beta_sd vector prior parameters log-beta standard deviation hyper-parameter - prior_pars_global_error_sigma vector prior parameters global error standard deviation - model name model functions generic S3 functions implemented class output . also generic function plots DE model parameters taken priors Now actually fit model extract estimates. provided trout data already form required hmde_assign_data function don‚Äôt need re-naming can pass directly. included two specialist diagnostic tools package give easy access RÃÇ\\hat{R} statistics chain convergence mixing. functions exclude RÃÇ\\hat{R} values associated generated quantites, 0 variance thus produce NAs.","code":"hmde_model(\"constant_multi_ind\") |>    names() #>  [1] \"n_obs\"                         \"n_ind\"                         #>  [3] \"y_obs\"                         \"obs_index\"                     #>  [5] \"time\"                          \"ind_id\"                        #>  [7] \"prior_pars_pop_log_beta_mean\"  \"prior_pars_pop_log_beta_sd\"    #>  [9] \"prior_pars_global_error_sigma\" \"model\"  print(hmde_model(\"constant_multi_ind\")) #> [1] \"Model: constant_multi_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $n_ind #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $ind_id #> NULL #>  #> $prior_pars_pop_log_beta_mean #> [1] 0 2 #>  #> $prior_pars_pop_log_beta_sd #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_multi_ind\" summary(hmde_model(\"constant_multi_ind\")) #> [1] \"Model: constant_multi_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $n_ind #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $ind_id #> NULL #>  #> $prior_pars_pop_log_beta_mean #> [1] 0 2 #>  #> $prior_pars_pop_log_beta_sd #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_multi_ind\" trout_constant_fit <- hmde_model(\"constant_multi_ind\") |>   hmde_assign_data(data = Trout_Size_Data)  |>   hmde_run(chains = 4, cores = 1, iter = 2000) #>  #> SAMPLING FOR MODEL 'constant_multi_ind' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.5 seconds (Warm-up) #> Chain 1:                0.418 seconds (Sampling) #> Chain 1:                0.918 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'constant_multi_ind' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 2.1e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.474 seconds (Warm-up) #> Chain 2:                0.327 seconds (Sampling) #> Chain 2:                0.801 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'constant_multi_ind' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2.1e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.506 seconds (Warm-up) #> Chain 3:                0.336 seconds (Sampling) #> Chain 3:                0.842 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'constant_multi_ind' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.483 seconds (Warm-up) #> Chain 4:                0.401 seconds (Sampling) #> Chain 4:                0.884 seconds (Total) #> Chain 4: # Returns a list of R_hat values hmde_extract_Rhat(trout_constant_fit) #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0004539          1.0005732          1.0012602          1.0000505  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0012108          1.0010668          1.0006413          1.0005610  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0016078          1.0015231          1.0003054          1.0004748  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0015254          1.0019810          1.0008454          1.0007235  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0002387          1.0003916          1.0006264          1.0004244  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0015734          1.0014534          1.0014780          1.0021080  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0003817          1.0000325          1.0023748          1.0018402  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0006403          1.0002645          1.0004623          1.0006357  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0011184          1.0006391          1.0001356          1.0012268  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0001768          1.0006285          1.0004399          1.0004367  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0005651          1.0008517          1.0010770          1.0009083  #>            ind_y_0            ind_y_0            ind_y_0            ind_y_0  #>          1.0032166          1.0017850          1.0019176          1.0014497  #>            ind_y_0            ind_y_0           ind_beta           ind_beta  #>          1.0012765          1.0018513          1.0020047          1.0011155  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0015634          1.0010684          1.0012418          1.0007665  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0035289          1.0010125          1.0012686          1.0007850  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0013931          1.0000464          1.0013710          1.0005725  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0012888          1.0015173          1.0020138          1.0005129  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0007365          1.0014100          1.0016766          1.0024173  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0004251          1.0041030          1.0012892          1.0007529  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0010654          1.0008596          1.0024632          1.0016998  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0016082          1.0013550          1.0010371          1.0008213  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0003897          1.0007614          1.0015092          1.0015652  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0011976          1.0008448          1.0010730          0.9999155  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0010286          1.0015635          1.0023487          1.0025764  #>           ind_beta           ind_beta           ind_beta           ind_beta  #>          1.0010962          1.0024324          1.0007661          1.0014566  #>  pop_log_beta_mean    pop_log_beta_sd global_error_sigma              y_hat  #>          1.0019318          1.0073849          1.0015913          1.0004539  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0000235          1.0004717          1.0010557          1.0005732  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0000637          1.0008320          1.0013675          1.0012602  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0003900          1.0008886          1.0008939          1.0000505  #>              y_hat              y_hat              y_hat              y_hat  #>          0.9998530          1.0012108          1.0004242          1.0008494  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0009089          1.0010668          1.0005948          1.0006413  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0006603          1.0005610          1.0004597          1.0016078  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0025263          1.0015231          1.0023732          1.0022525  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0003054          1.0001992          1.0004748          1.0004049  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0015254          1.0010280          1.0005446          1.0003908  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0019810          1.0007279          1.0008454          1.0018637  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0012440          1.0007235          1.0004590          1.0012320  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0002387          1.0007605          1.0016630          1.0003916  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0005344          1.0006264          1.0005825          1.0004124  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0004244          1.0017327          1.0016782          1.0015734  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0003822          1.0014534          1.0017536          1.0014780  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0006841          1.0021080          1.0020743          1.0003817  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0007061          1.0000325          1.0006070          1.0008725  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0010703          1.0023748          1.0018517          1.0024947  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0018402          1.0006799          1.0006403          1.0000556  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0002645          1.0003646          1.0004623          1.0003871  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0006357          1.0006344          1.0011184          1.0010273  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0006391          1.0000110          0.9998934          1.0003643  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0001356          1.0011353          1.0012268          1.0020884  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0001768          1.0014405          1.0006285          1.0008154  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0014945          1.0004399          1.0014642          1.0007587  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0004367          1.0007741          1.0008878          1.0007374  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0005651          1.0007379          1.0008517          1.0006263  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0006126          1.0010770          1.0016399          1.0013652  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0009083          1.0000006          1.0007810          1.0032166  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0032446          1.0017850          1.0006857          1.0005928  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0019176          1.0016698          1.0005177          1.0014497  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0015011          1.0017601          1.0018282          1.0012765  #>              y_hat              y_hat              y_hat              y_hat  #>          1.0013616          1.0015882          1.0010607          1.0018513  #>              y_hat              y_hat               lp__  #>          1.0004130          1.0005609          1.0051033  # Returns a histogram of R_hat values hmde_plot_Rhat_hist(trout_constant_fit)"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"inspect-estimates","dir":"Articles","previous_headings":"SUSTAIN trout data","what":"Inspect estimates","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"model finished running, can extract model estimates look distribution estimated sizes, estimated growth increments, annualised growth rates level sizes time. First, let‚Äôs quick data wrangling calculate parameters interest. Now can look distribution estimated parameter creating histograms  can see negative growth increments gone! fit positive growth function (f=Œ≤>0f = \\beta > 0) model actually estimate negative growth increments.","code":"trout_constant_estimates <- hmde_extract_estimates(                                                                   fit = trout_constant_fit,                                  input_measurement_data = Trout_Size_Data) measurement_data_transformed <- trout_constant_estimates$measurement_data %>%   group_by(ind_id) %>%   mutate(     delta_y_obs = y_obs - lag(y_obs),     obs_interval = time - lag(time),     obs_growth_rate = delta_y_obs/obs_interval,     delta_y_est = y_hat - lag(y_hat),     est_growth_rate = delta_y_est/obs_interval   ) %>%   ungroup() est_hist_y_hat <- histogram_func(measurement_data_transformed, y_hat,                 \"Estimated size distribution\",                xlab = \"Size (cm)\",                bins = 5)  est_hist_delta_y_est <-  histogram_func(measurement_data_transformed, delta_y_est,                 \"Estimated growth  \\n increments\",                xlab = \"Growth increment (cm)\",                bins = 5)  est_hist_growth_rate <- histogram_func(measurement_data_transformed, est_growth_rate,                 \"Estimated annualised growth rate distribution\", xlab = \"Growth rate (cm/yr)\",                bins = 5)  (est_hist_y_hat + est_hist_delta_y_est) / est_hist_growth_rate"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"r2","dir":"Articles","previous_headings":"SUSTAIN trout data > Inspect estimates","what":"R2R^2","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"can also directly compare observed sizes time estimated values. can use R2R^2 calculated (yij,YÃÇij)(y_{ij}, \\hat{Y}_{ij}), inspect can look plots sizes time. R2R^2 statistic metric primarily used linear regression measures proportion (ie. decimal value [0,1] interval) variance one coordinate can explained regression model. context, interpret strongly fitted observed values agree. don‚Äôt expect perfect agreement ‚Äì R2=1R^2=1 ‚Äì don‚Äôt get perfect agreement. O‚ÄôBrien, Warton, Falster (2024) showed change observed fitted values can actually correct measurement errors size, disagreement bad thing overall. next block, looking 5 random individuals start plotting every individuals‚Äô sizes time can get messy.","code":"#Quantitative R^2 cor(measurement_data_transformed$y_obs, measurement_data_transformed$y_hat)^2 #> [1] 0.9540111 r_sq_est <- cor(trout_constant_estimates$measurement_data$y_obs,                           trout_constant_estimates$measurement_data$y_hat)^2 r_sq <- paste0(\"R^2 = \",                 signif(r_sq_est,                       digits = 3))  obs_est_size_plot <- ggplot(data = trout_constant_estimates$measurement_data,         aes(x = y_obs, y = y_hat)) +   geom_point(shape = 16, size = 1, colour = \"green4\") +   xlab(\"Y obs.\") +   ylab(\"Y est.\") +   geom_abline(slope = 1, linetype = \"dashed\") +   annotate(\"text\", x = 45, y = 80,             label = r_sq) +   theme_classic() obs_est_size_plot #Plots of size over time for a sample of 5 individuals size_over_time_plot <- hmde_plot_obs_est_inds(n_ind_to_plot = 5,                        measurement_data = trout_constant_estimates$measurement_data) size_over_time_plot"},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"individual-growth-functions-beta","dir":"Articles","previous_headings":"SUSTAIN trout data","what":"Individual growth functions (Œ≤\\beta)","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"level individuals interested distribution Œ≤\\beta estimates, align estimated annualised growth rates ‚Äôs precisely represent. one way visualise fitted growth functions order see compare observed sizes.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/constant-growth.html","id":"population-hyper-parameters","dir":"Articles","previous_headings":"SUSTAIN trout data","what":"Population hyper-parameters","title":"Case study 1: Constant growth with SUSTAIN Trout data","text":"also get estimates population-level hyper-parameters govern distribution Œ≤\\beta ‚Äì Œº\\mu œÉ\\sigma log-normal distribution. calculated context log-transformed parameters easiest way interpret Œº\\mu back-transform exponentiation, easily transfer œÉ\\sigma. CIs output posterior credible intervals taken central 95% quantiles posterior samples. species-level data can say average annual growth rate species estimated 2.4cm/yr, 95% posterior CI (1.83, 3.04). fit constant growth model ‚Äôs much can say growth behaviour.","code":"#Mean of normal distribution trout_constant_estimates$population_data$mean[1] #Raw value #> [1] 0.8812017 print(paste0(\"95% CI for mean log growth: (\",               trout_constant_estimates$population_data$CI_lower[1], \" , \",              trout_constant_estimates$population_data$CI_upper[1], \")\")) #Raw CI #> [1] \"95% CI for mean log growth: (0.577979967794788 , 1.11797940744988)\"  exp(trout_constant_estimates$population_data$mean[1]) #In cm/yr units #> [1] 2.413799 print(paste0(\"95% CI for mean growth in cm/yr: (\",               exp(trout_constant_estimates$population_data$CI_lower[1]), \" , \",              exp(trout_constant_estimates$population_data$CI_upper[1]), \")\")) #> [1] \"95% CI for mean growth in cm/yr: (1.78243421713959 , 3.05866763409531)\"  #Standard deviation of underlying normal distribution trout_constant_estimates$population_data$mean[2] #> [1] 0.4846497 print(paste0(\"95% CI for log growth standard deviation: (\",               trout_constant_estimates$population_data$CI_lower[2], \" , \",              trout_constant_estimates$population_data$CI_upper[2], \")\")) #Raw CI #> [1] \"95% CI for log growth standard deviation: (0.173827701537664 , 0.8358819473229)\""},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"load-dependencies","dir":"Articles","previous_headings":"","what":"Load dependencies","title":"Here be dragons","text":"vignette demonstrates interaction errors numerical integration methods MCMC sampling produces bimodal posterior distribution result numerical error. stumbled across problem documenting , account package either using analytic solutions, numerical methods adaptive step sizes analytic solutions available. underlying issue , given errors chosen numerical integration method, two sets parameters differential equation ff give ‚Äú‚Äù (second) output Y(tj+1)=Y(tj)+‚à´tjtj+1f(Y(t),ùõâ)dt(1)Y(t_{j+1}) = Y(t_j) + \\int_{t_j}^{t_{j+1}} f(Y(t), \\boldsymbol{\\theta})\\,dt\\qquad (1) MCMC sampler unable meaningfully distinguish parameter combinations. see practice chains converging extremely different parameter combinations, one `true‚Äô combination, wrong produces YÃÇ(tj)\\hat{Y}(t_j) values due numerical error. Thus, form non-identifiability arises numerical errors longitudinal model based Equation (1) separate issues non-identifiability, currently -explored literature. demonstration use Runge-Kutta 4th order numerical method () different step sizes show even ‚Äòsmall‚Äô step sizes can give problems. important state ‚Äú‚Äù Y(t)Y(t) values context means within statistical error . assume data consists observations form yjy_{j} time tjt_j look like yj=Y(tj)+error,y_j = Y(t_j) + \\text{error}, finite level precision. numerical method may produce estimated values YÃÇ(tj)\\hat{Y}(t_j) differ amount much smaller level precision observation error different parameter combinations, due imprecision measurement process MCMC sampler meaningfully distinguish estimates. demonstration simulate data though measured centimetres. use rounding produce simulated data measurement precision 0.1cm, error ùí©(0,0.1)\\mathcal{N}(0, 0.1), analogous 1mm measurement precision approximate standard deviation real-world source data used O‚ÄôBrien, Warton, Falster (2024).","code":"#remotes::install_github(\"traitecoevo/hmde\")  library(hmde) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(deSolve) library(mixtools) #> mixtools package, version 2.0.0.1, Released 2022-12-04 #> This package is based upon work supported by the National Science Foundation under Grant No. SES-0518772 and the Chan Zuckerberg Initiative: Essential Open Source Software for Science (Grant No. 2020-255193). library(MASS) #>  #> Attaching package: 'MASS' #> The following object is masked from 'package:dplyr': #>  #>     select"},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"the-model","dir":"Articles","previous_headings":"","what":"The model","title":"Here be dragons","text":"implementing longitudinal model form Equation (1) within hierarchical Bayesian longitudinal model f(Y(t),Œ≤0,Œ≤1)=Œ≤0‚àíŒ≤1Y(t)(2)f(Y(t), \\beta_0, \\beta_1) = \\beta_0 - \\beta_1 Y(t)\\qquad (2) Equation (2) known produce pathological behaviour numerical methods (Butcher 2016), serves ideal simple example interaction pathologies MCMC sampling process. purpose estimation shift Equation (2) mean observed size gives ffit(Y(t),Œ≤c,Œ≤1)=Œ≤c‚àíŒ≤1(Y(t)‚àíy‚Äæ),f_{fit}(Y(t), \\beta_c, \\beta_1) = \\beta_c - \\beta_1(Y(t) - \\bar{y}), back-transformation Œ≤0=Œ≤c+Œ≤1y‚Äæ.\\beta_0 = \\beta_c + \\beta_1 \\bar{y}. attempting estimate parameters Œ≤0\\beta_0 Œ≤1\\beta_1 observations yjy_j, based estimating YÃÇj\\hat{Y}_j given prior distribution yj‚àºùí©(YÃÇj,0.1).y_j \\sim \\mathcal{N}(\\hat{Y}_j, 0.1). looking single individual, prior distributions default parameters Œ≤1,Œ≤c‚àºlogùí©(0,2),\\beta_1, \\beta_c \\sim \\log\\mathcal{N}(0,2), enforce Œ≤k>0\\beta_k > 0.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"simulating-data","dir":"Articles","previous_headings":"","what":"Simulating data","title":"Here be dragons","text":"demo code use Œ≤0=10\\beta_0 = 10 Œ≤1=1\\beta_1 = 1, gives asymptotic size 10. wish experiment values, input next block rest run based . use analytic solution simulate true sizes time, add measurement error round chosen measurement precision 0.1cm give sequence observations time become y_obs data model fit. Notice y_obs can produces values bigger theoretical asymptotic size Œ≤0/Œ≤1\\beta_0/\\beta_1 due error. analytic solution produce observations adding measurement error rounding precision 0.1.   note error precision: bad behaviour occurs even use unrounded data precision R offers much smaller error. can test uncommenting line rounds data /changing measurement error standard deviation. chosen values, rounding, intended demonstrate problem may occur realistic precision error.","code":"#Change these values to change the model parameters. Must be positive values. beta_0 <- 10 beta_1 <- 1  #True initial condition true_y_0 <- 1 max_time <- 9 time <- 0:max_time  #Analytic solution analytic_solution <- function(x = NULL, pars = NULL){ #Pars is list of beta_0, beta_1, y_0   return(     (pars[[1]]/pars[[2]]) + (pars[[3]] - (pars[[1]]/pars[[2]])) * exp(-pars[[2]] * x)   ) } true_pars <- list(   beta_0 = beta_0,   beta_1 = beta_1,   true_y_0 = true_y_0 ) true_args_list <- list(pars = c(beta_0,                              beta_1,                              true_y_0))  y_true <- analytic_solution(time, true_pars) #Produce observations with error and limited precision y_obs <- round(y_true + rnorm(length(y_true), 0, 0.1), digits = 1)  #Unrounded data if needed #y_obs <- y_true + rnorm(length(y_true), 0, 0.1)  #Observed data frame obs_data_frame <- tibble(   time = time,   y_obs = y_obs,   obs_index = 1:length(y_obs) )  #Have a look at the true and 'observed' data plot_data <- tibble(   x = c(time, time),   y = c(y_true,y_obs),   Data = c(rep(\"True sizes\", times = length(y_true)),              rep(\"Obs. sizes\", times = length(y_obs))) )  sizes_over_time <- ggplot(plot_data, aes(x = x, y = y, group = Data)) +   geom_point(aes(colour = Data, shape = Data), size = 2) +   geom_line(aes(colour = Data, linetype = Data), linewidth = 1) +   scale_linetype_manual(values = c(\"dashed\", \"dotted\")) +   ylim(0, 10.5) +   labs(x = \"Time\", y = \"Y\") +   theme_classic() +   theme(legend.position = \"inside\",         legend.position.inside = c(0.7, 0.3)) sizes_over_time #Have a look at the observations against the analytic solution analytic_observed <- ggplot(obs_data_frame, aes(x = time, y = y_obs)) +   geom_function(fun=analytic_solution, args = true_args_list,                 linewidth = 1, colour = \"black\") +   geom_point(colour = \"darkorchid\", size = 3) +   geom_line(colour = \"darkorchid\", linewidth = 1,             linetype = \"dashed\") +   labs(x = \"Time\", y = \"Y\",        title = \"Data simulation\") +   ylim(0, 10.5) +   theme_classic() analytic_observed"},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"implementing-models-and-collecting-posterior-estimates","dir":"Articles","previous_headings":"","what":"Implementing models and collecting posterior estimates","title":"Here be dragons","text":"section going run sequence sets models. first batch checking existence bimodal posterior distributions across different step sizes numerical method. use different numerical method see problem persists. Lastly, use different means parameter priors see posterior can constrained methods.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"step-size-data","dir":"Articles","previous_headings":"Implementing models and collecting posterior estimates","what":"Step size data","title":"Here be dragons","text":"‚Äôre going run 100 fits step size 1 using custom RK4 solver single chain . chain expected converge parameter combination gives estimated YÃÇ(tj)\\hat{Y}(t_j) close analytic solution, combination converged random. single chains can fall numerical error trap, easiest way identify trap extract estimates afterwards. fit takes seconds run, allow several minutes following block. likely diagnostic problems part explore ignoring . Divergent transitions particular expected different parameter estimates see. Results hidden block.","code":"runs <- 100 step_size = 0.5 par_est_tibble <- tibble(run = c(),                          step_size = c(),                          beta_0 = c(),                          beta_1 = c())  for(i in 1:runs){   #Run the model   suppressWarnings(     fit <- hmde_model(\"affine_single_ind\") |>     hmde_assign_data(n_obs = nrow(obs_data_frame),                      y_obs = obs_data_frame$y_obs,                      obs_index = obs_data_frame$obs_index,                      time = obs_data_frame$time,                      y_bar = mean(obs_data_frame$y_obs),                      step_size = step_size,                      int_method = 1)  |>  #RK4     hmde_run(chains = 1, cores = 1, iter = 2000)   )      #Extract parameter estimates   ests <- hmde_extract_estimates(fit = fit,                                  input_measurement_data = obs_data_frame)      temp <- tibble(     run = i,     step_size = step_size,     beta_0 = ests$individual_data$ind_beta_0_mean,     beta_1 = ests$individual_data$ind_beta_1_mean   )      par_est_tibble <- rbind(par_est_tibble, temp) }"},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"Here be dragons","text":"going fit finite mixture model tell us clustering posterior distributions. assume two clusters (can check scatter plots), one close true values distance away much larger estimates , use mean rows $\\hat{\\beta_}_0 > mean(\\hat{\\beta_}_0)$ starting value iterative process avoid singularities. overall mean estimates works threshold extreme values bimodality distance clusters.  get bimodality posterior distributions. look multiple step sizes see smaller step sizes push second cluster away. Bias estimates closest true values due measurement error ‚Äòobserved‚Äô data fits. second mode estimates arises numerical integration error verify shortly. extreme bimodality posterior consistent behaviour, even though point second mode shifts based step size. aesthetics plots. use scatter plots clusters qualitative analysis. clusters distant , tight around means, separate plots. mixture models gives classification point data use filter observations. clusters distant can use heuristics $\\hat{\\beta_}_0 > 2\\beta_0$ agree perfectly cluster analysis. contours scatter plot come data simulated cluster‚Äôs multivariate normal distribution identified finite mixture model. can double-check numerical error using independent solver step size. use deSolve package implementation RK4 allows us choose step sizes using time parameter.","code":"step_size_mix_models <- list() step_size_mix_model_plots <- list() step_size_mix_models_par_ests <- tibble(   good_beta_0 = c(),   good_beta_1 = c(),   error_beta_0 = c(),   error_beta_1 = c(),   step_size = c(),   error_fraction = c(),   dist = c() )  for(i in 1:length(unique(par_est_tibble$step_size))){   #Get data for single step size   step_size_selected <- unique(par_est_tibble$step_size)[i]      analysis_data <- par_est_tibble %>%     filter(step_size == step_size_selected)      #Get some extreme estimates   possible_error <- analysis_data %>%     filter(beta_0 > mean(analysis_data$beta_0))      #To speed up the iterative algorithm we provide some initial conditions   mu <- list( #Means from true parameters and extreme estimates     true = c(beta_0, beta_1),     error = c(mean(possible_error$beta_0),                mean(possible_error$beta_1))   )      #Fit multivariate normal finite mixture model to the estimates   step_size_mix_models[[i]] <- mvnormalmixEM(x = analysis_data[,c(3,4)], mu = mu)      print(paste0(\"Summary of mixture model for step size \", step_size_selected))   print(summary(step_size_mix_models[[i]]))      step_size_mix_model_plots[[i]] <- plot(step_size_mix_models[[i]],                                 whichplots = 2,                                 xlab2 = \"Beta 0\",                                 ylab2 = \"Beta 1\")      dist_table <- tibble( #Data to calculate distance     b_0 = c(step_size_mix_models[[i]]$mu[[2]][1],              step_size_mix_models[[i]]$mu[[1]][1]),     b_1 = c(step_size_mix_models[[i]]$mu[[2]][2],              step_size_mix_models[[i]]$mu[[1]][2])   )      #Extract values   step_size_mix_models_par_ests_temp <- tibble(     good_beta_0 = step_size_mix_models[[i]]$mu[[1]][1],     good_beta_1 = step_size_mix_models[[i]]$mu[[1]][2],     error_beta_0 = step_size_mix_models[[i]]$mu[[2]][1],     error_beta_1 = step_size_mix_models[[i]]$mu[[2]][2],     step_size = step_size_selected,     error_prob = step_size_mix_models[[i]]$lambda[2],     dist = dist(dist_table)   )      step_size_mix_models_par_ests <- rbind(step_size_mix_models_par_ests,                                           step_size_mix_models_par_ests_temp) } #> number of iterations= 3  #> [1] \"Summary of mixture model for step size 0.5\" #> summary of mvnormalmixEM object: #>          comp 1   comp 2 #> lambda 0.670000  0.33000 #> mu1    9.810421 49.16390 #> mu2    0.980554  4.92054 #> loglik at estimate:  992.063  #> NULL #Have a look at the estimates step_size_mix_models_par_ests #> # A tibble: 1 √ó 7 #>   good_beta_0 good_beta_1 error_beta_0 error_beta_1 step_size error_prob dist    #>         <dbl>       <dbl>        <dbl>        <dbl>     <dbl>      <dbl> <dist>  #> 1        9.81       0.981         49.2         4.92       0.5       0.33 39.550‚Ä¶ legend_spec <- tibble(   step_size_name = c(\"0.5\", \"0.25\", \"0.125\"),   step_size = c(0.5, 0.25, 0.125),   x = c(-10, -10, -10),   y = c(-10, -10, -10),   colours = c(\"#f8766d\", \"#00ba38\", \"#609cff\"),   linetypes = c(\"longdash\", \"dashed\", \"dotted\"),   shapes = c(19, 17, 15) )   legend_spec_with_true <- tibble(   step_size_name = c(\"0.5\", \"0.25\", \"0.125\", \"True pars\"),   step_size = c(0.5, 0.25, 0.125, NA),   x = c(-10, -10, -10, -10),   y = c(-10, -10, -10, -10),   colours = c(\"#f8766d\", \"#00ba38\", \"#609cff\", \"black\"),   linetypes = c(\"longdash\", \"dashed\", \"dotted\", \"solid\"),   shapes = c(19, 17, 15, 3) )  for(i in 1:nrow(legend_spec)){   fancy_name_no_step_size <-    paste0(\"Beta_0 = \",          signif(step_size_mix_models_par_ests$error_beta_0[i],                 digits = 3),          \",\\n Beta_1 = \",          signif(step_size_mix_models_par_ests$error_beta_1[i],                               digits = 3))   legend_spec$fancy_name_no_step_size[i] <- fancy_name_no_step_size   legend_spec_with_true$fancy_name_no_step_size[i] <- fancy_name_no_step_size      fancy_name <- paste0(\"Step size \", step_size_mix_models_par_ests$step_size[i],                         \"\\n\", fancy_name_no_step_size)      legend_spec$fancy_name[i] <- fancy_name   legend_spec_with_true$fancy_name[i] <- fancy_name } #> Warning: Unknown or uninitialised column: `fancy_name_no_step_size`. #> Unknown or uninitialised column: `fancy_name_no_step_size`. #> Warning: Unknown or uninitialised column: `fancy_name`. #> Unknown or uninitialised column: `fancy_name`.  legend_spec_with_true$fancy_name_no_step_size[4] <-   paste0(\"Beta_0 = \",          beta_0,          \",\\n Beta_1 = \",          beta_1)  legend_spec_with_true$fancy_name[4] <-   paste0(\"True values\\n Beta_0 = \",          beta_0,          \",\\n Beta_1 = \",          beta_1) scatterplot_errors_only <- list() scatterplot_good_only <- list()  for(i in 1:length(unique(par_est_tibble$step_size))){   step_size_select <- unique(par_est_tibble$step_size)[i]      plot_data <- par_est_tibble %>%     filter(step_size == step_size_select)      #Get classification from mixture model   plot_data$good_est <- step_size_mix_models[[i]][[\"posterior\"]][,1]      error_ests_scatter <- plot_data %>%     filter(!as.logical(good_est))   good_ests_scatter <- plot_data %>%     filter(as.logical(good_est))      #Scatter plot of erroneous parameters   xpos <- (min(error_ests_scatter$beta_0) +               0.2*(max(error_ests_scatter$beta_0) -                      min(error_ests_scatter$beta_0)))   ypos <- (max(error_ests_scatter$beta_1) -               0.1*(max(error_ests_scatter$beta_1) -                      min(error_ests_scatter$beta_1)))   norm_data <- as.data.frame(mvrnorm(n = 10000,                        mu = step_size_mix_models[[i]][[\"mu\"]][[2]],                        Sigma = step_size_mix_models[[i]][[\"sigma\"]][[2]]))   names(norm_data) <- c(\"beta_0\", \"beta_1\")        scatterplot_errors_only[[i]] <- ggplot(data = error_ests_scatter,                                           aes(x = beta_0, y = beta_1)) +     geom_point(colour = legend_spec$colours[i],                 shape = legend_spec$shapes[i],                 alpha = 0.5,                size = 2) +     geom_density_2d(data = norm_data, colour = \"black\") +     labs(x = \"beta_0 est.\",            y = \"beta_1 est.\",            title = \"Second cluster\") +     annotate(\"text\", x = xpos, y = ypos,               label = paste0(\"Probability: \\n\",                             step_size_mix_models_par_ests$error_prob[i])) +     theme_classic()      #Scatter plot of good parameter estimates   xpos <- (min(good_ests_scatter$beta_0) +               0.2*(max(good_ests_scatter$beta_0) -                      min(good_ests_scatter$beta_0)))   ypos <- (max(good_ests_scatter$beta_1) -               0.1*(max(good_ests_scatter$beta_1) -                      min(good_ests_scatter$beta_1)))   norm_data <- as.data.frame(mvrnorm(n = 10000,                        mu = step_size_mix_models[[i]][[\"mu\"]][[1]],                        Sigma = step_size_mix_models[[i]][[\"sigma\"]][[1]]))   names(norm_data) <- c(\"beta_0\", \"beta_1\")      scatterplot_good_only[[i]] <- ggplot(data = good_ests_scatter,                                           aes(x = beta_0, y = beta_1)) +     geom_point(colour = legend_spec$colours[i],                 shape = legend_spec$shapes[i],                 alpha = 0.5,                size = 2) +     geom_density_2d(data = norm_data, colour = \"black\") +     labs(x = \"beta_0 est.\",            y = \"beta_1 est.\",            title = \"First cluster\") +     annotate(\"text\", x = xpos, y = ypos,               label = paste0(\"Probability: \\n\",                             (1-step_size_mix_models_par_ests$error_prob[i]))) +       theme_classic() } #install.packages(\"deSolve\") library(deSolve)  #Create DE function DE <- function(Time, State, Pars) { #Implementation of DE   with(as.list(c(State, Pars)), {     dY <- beta_0 - beta_1 * Y      return(list(c(dY)))   }) }"},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"second-cluster-analysis","dir":"Articles","previous_headings":"Analysis","what":"Second cluster analysis","title":"Here be dragons","text":"want look behaviour numerical method bad estimate clusters. project forward initial condition using chosen step size, bad parameter combination, see happens. can compare numerical solution true sizes time, analytic solution bad parameter estimates. First generate numerical analytic solution data. figure shows estimated sizes time bad parameter combinations across different step sizes, compared true values. indistinguishable values. look extremely closely get deviation due parameter bias, statistically relevant process. demonstrate smaller step size test method enough identify bad estimates, show RK4 step size 0.001 diverges true sizes time. lines plot based small step size numerical estimates, points come Y(tj)Y(t_j) values discrete observation times.  two plots showing ODEs analytic solutions bad estimates compared true parameter values. plot ODEs exploit fact straight lines rather plotting functions properly.  limiting behaviour Œ≤0/Œ≤1\\beta_0/\\beta_1 consistent, changes fast line approaches asymptote.","code":"yini  <- c(Y = true_y_0) #Initial condition y_over_time <- tibble(model=\"True Sizes\",                       y_analytic = y_true,                       y_numeric = y_true,                       time = 0:max_time,                       beta_0_par = beta_0,                       beta_1_par = beta_1                       )  #Generate Y(t) with RK4 for(i in 1:nrow(step_size_mix_models_par_ests)){   pars_combo <- c(beta_0 = step_size_mix_models_par_ests$error_beta_0[i],                     beta_1 = step_size_mix_models_par_ests$error_beta_1[i])   times <- seq(0, max_time, by = step_size_mix_models_par_ests$step_size[i])      solution_pars <- c(pars_combo, true_y_0)   y_true_temp <- analytic_solution(times, solution_pars)        numerical_output <- ode(yini, times, DE, pars_combo, method = \"rk4\")      y_over_time_temp <- tibble(     model = step_size_mix_models_par_ests$step_size[i],     y_analytic = y_true_temp,     y_numeric = numerical_output[,2],     time = times,     beta_0_par = step_size_mix_models_par_ests$error_beta_0[i],     beta_1_par = step_size_mix_models_par_ests$error_beta_1[i]   )      y_over_time <- rbind(y_over_time, y_over_time_temp) } y_over_time_filtered <- y_over_time %>%   filter(time %in% 0:max_time)    #Plot sizes over time for all models compare_sizes_over_time <- ggplot(y_over_time_filtered,                                    aes(x=time, y=y_numeric, group_by = as.factor(model))) +   geom_point(aes(colour = as.factor(model),              shape = as.factor(model)),              alpha=0.5, size = 2, stroke = 1.5) +   geom_line(aes(colour = as.factor(model)), alpha=0.5, linewidth = 1) +   scale_colour_manual(values = legend_spec_with_true$colours) +   scale_shape_manual(values = legend_spec_with_true$shapes) +   labs(x = \"Time\", y = \"Y(t)\", title = \"Estimated Y(t) with bad parameters\",        colour = \"Step size\", shape = \"Step size\") +   theme_classic() +   theme(legend.position = \"inside\",         legend.position.inside = c(0.7, 0.3))  compare_sizes_over_time #Generate y(t) with RK4 given the parameter estimates y_over_time_smallstep <- tibble(model=legend_spec_with_true$fancy_name[4],                       y_hat = y_true,                       time = 0:max_time                       )  for(i in 1:nrow(step_size_mix_models_par_ests)){   pars_combo <- c(beta_0 = step_size_mix_models_par_ests$error_beta_0[i],                     beta_1 = step_size_mix_models_par_ests$error_beta_1[i])     times <- seq(0, max_time, by = 0.001)          numerical_output <- ode(yini, times, DE, pars_combo, method = \"rk4\")          y_over_time_temp <- tibble(       model = legend_spec_with_true$fancy_name_no_step_size[i],       y_hat = numerical_output[,2],       time = times     )          y_over_time_smallstep <- rbind(y_over_time_smallstep, y_over_time_temp) }  point_data <- y_over_time_smallstep %>%   filter(time %in% 0:max_time)  #Plot sizes over time compare_sizes_over_time_smallstep <- ggplot(y_over_time_smallstep,                                    aes(x=time, y=y_hat, grouping = as.factor(model))) +   geom_line(aes(colour = as.factor(model),                 linetype = as.factor(model)), alpha=0.5, linewidth = 1) +   geom_point(data = point_data,              aes(colour = as.factor(model),              shape = as.factor(model)),              alpha=0.5, size = 2, stroke = 1.5) +   geom_function(fun=analytic_solution, args=true_args_list,                 colour=\"black\",                 linetype = \"solid\",                 linewidth=1) +   scale_shape_manual(values = legend_spec_with_true$shapes) +   scale_colour_manual(values = legend_spec_with_true$colours) +   scale_linetype_manual(values = c(legend_spec$linetypes, NA)) +   labs(x = \"Time\", y = \"Y(t)\", title = \"Small step size\",        colour = \"Parameters\",         shape = \"Parameters\",        linetype = \"Parameters\") +   theme_classic() +   theme(legend.position = \"inside\",         legend.position.inside = c(0.7, 0.4),         legend.key.spacing.y = unit(2, 'mm')) +   guides(colour = guide_legend(byrow = TRUE))  compare_sizes_over_time_smallstep #> Warning: Multiple drawing groups in `geom_function()` #> ‚Ñπ Did you use the correct group, colour, or fill aesthetics? #Get asymptotic size step_size_mix_models_par_ests$Y_max <- step_size_mix_models_par_ests$error_beta_0/step_size_mix_models_par_ests$error_beta_1  #Build points for start and end of lines plot_data <- tibble(   x = c(0, (beta_0/beta_1),          rep(0, times = nrow(step_size_mix_models_par_ests)),          step_size_mix_models_par_ests$Y_max),   y = c(beta_0, 0,          step_size_mix_models_par_ests$error_beta_0,          rep(0, times = nrow(step_size_mix_models_par_ests))),   step_size = c(\"True pars\", \"True pars\",                  step_size_mix_models_par_ests$step_size,                  step_size_mix_models_par_ests$step_size) )  #Plot DEs  error_de_plot <- ggplot(data = plot_data, aes(x,y)) +   geom_line(aes(colour = as.factor(step_size),                 linetype = as.factor(step_size)),             linewidth = 1) +   scale_colour_manual(values = c(legend_spec$colours[3:1], \"black\")) +   scale_linetype_manual(values = c(legend_spec$linetypes[3:1], \"solid\")) +   labs(title = \"ODEs\",        x = \"Y(t)\", y = \"f\",         colour = \"Step size\",         linetype = \"Step size\") +   theme_classic() +   theme(legend.position = \"inside\",         legend.position.inside = c(0.7, 0.7)) error_de_plot #Plot analytic solutions error_solution_plot <- ggplot() +   geom_function(fun=analytic_solution, args=true_args_list,                   colour=\"black\",                    linetype = \"solid\",                   linewidth=1)   for(i in 1:nrow(step_size_mix_models_par_ests)){ #Add the analytic solutions   args_list <- list(pars=c(step_size_mix_models_par_ests$error_beta_0[i],                            step_size_mix_models_par_ests$error_beta_1[i],                            true_y_0))   error_solution_plot <- error_solution_plot +     geom_function(fun=analytic_solution, args=args_list,                   colour=legend_spec$colours[i],                    linetype = legend_spec$linetypes[i],                   linewidth=1) }  error_solution_plot <- error_solution_plot +   geom_line(data = legend_spec_with_true,             linewidth=1,             aes(colour = fancy_name_no_step_size,                 linetype = fancy_name_no_step_size,                 x = x, y = y)) +   scale_colour_manual(values = c(legend_spec_with_true$colours[4],                                   legend_spec$colours[c(2,3,1)])) +   scale_linetype_manual(values = c(legend_spec_with_true$linetypes[4],                                     legend_spec$linetypes[c(2,3,1)])) +   xlim(0, max_time) +   ylim(true_y_0, (beta_0/beta_1+0.5)) +   labs(x = \"Time\", y = \"Y(t)\",         title = \"Analytic solutions\",        colour = \"Parameters\",         linetype = \"Parameters\") +   theme_classic() +   theme(legend.position = \"inside\",         legend.position.inside = c(0.7, 0.4),         legend.key.spacing.y = unit(2, 'mm')) +   guides(colour = guide_legend(byrow = TRUE))  error_solution_plot #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://traitecoevo.github.io/hmde/articles/here_be_dragons.html","id":"where-to-from-here","dir":"Articles","previous_headings":"","what":"Where to from here?","title":"Here be dragons","text":"purpose hmde package vignette part , account pathologies particular model using analytic solution von Bertalanffy equation. work needs done understand interaction numerical methods MCMC sampling. demonstrated problem exists, enough numerical stability true parameter values MCMC estimation moves around, need numerical stability potentially quite large part parameter space. good news simulated data posterior plots accurate numerical methods can least identify something going wrong.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"hmde","text":"hmde active development, can install stable, development version hmde GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"traitecoevo/hmde\")"},{"path":"https://traitecoevo.github.io/hmde/articles/hmde.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"hmde","text":"treat growth continuous rate change size, fit size-dependent growth functions. repeat survey data requires multiple measurements individuals time can connected size(tj+1)=size(tj)+growth(tj tj+1).\\begin{equation}\\tag{1}\\label{eqn_1} size(t_{j+1}) = size(t_{j}) + growth(\\text{}t_j\\text{ }t_{j+1}). \\end{equation} assume different individuals variation specifics growth function governed function parameters, individuals population function description.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde.html","id":"notation","dir":"Articles","previous_headings":"Overview","what":"Notation","title":"hmde","text":"notation express true size individual ii time tjt_j Yi(tj)Y_i(t_j), growth function ff, parameter individual ii Œ≤i\\beta_i. Equation can expressed Yi(tj+1)=Yi(tj)+‚à´tjtj+1f(Y(t),Œ≤i)dt\\begin{equation}\\tag{2}\\label{eqn_2_longitudinal} Y_i(t_{j+1}) = Y_i(t_j) + \\int_{t_j}^{t_{j+1}} f(Y(t), \\beta_i)\\,dt \\end{equation} integral adds growth intervening time. model use comes specific growth parameters describe. biologically interpretable others. don‚Äôt assume see true sizes, instead observed size yij=Yi(tj)+ error.y_{ij} = Y_i(t_j) + \\text{ error}. assumed normally distributed error hmde,proven reasonably robust simulation general size-dependent error model. details see O‚ÄôBrien, Warton, Falster (2024). Due hierarchical structure statistical model, distributions govern behaviour growth parameters. modeling single individual, don‚Äôt worry underlying distribution much. multiple individuals distribution hyper-parameters acts population-level feature, Œ≤i‚àºlogùí©(Œº,œÉ)\\beta_i \\sim \\log\\mathcal{N}(\\mu, \\sigma) example, can examine behaviour mean standard deviation population-level features.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde.html","id":"hmde-supported-growth-functions","dir":"Articles","previous_headings":"","what":"hmde supported growth functions","title":"hmde","text":"Constant growth Von Bertalanffy Canham growth function, implementation model growth single multiple individuals.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde.html","id":"workflow","dir":"Articles","previous_headings":"","what":"Workflow","title":"hmde","text":"Broadly, workflow hmde : Wrangle data required format chosen model, Pass data model function runs sampling Stan‚Äôs MCMC algorithms. Inspect analysis returned Stan fit object. demonstrate workflow using case studies uses three growth functions supported hmde. can find website can view R using: case study, discuss growth function chosen context survey process data availability key factor determining functions can used. discuss mathematical statistical theory depth, interest, check vignette ‚Äòhmde Mathematicians‚Äô check methodology paper O‚ÄôBrien, Warton, Falster (2024).","code":"vignettes(\"constant-growth\") vignettes(\"von-bertalanffy\") vignettes(\"canham\")"},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/articles/hmde_for_mathematicians.html","id":"getting-started-with-hmde","dir":"Articles","previous_headings":"","what":"Getting started with {hmde}","title":"hmde for Mathematicians","text":"‚Äòhmde‚Äô active development, can install development version ‚Äòhmde‚Äô GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"traitecoevo/hmde\") library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(hmde)"},{"path":"https://traitecoevo.github.io/hmde/articles/hmde_for_mathematicians.html","id":"the-theory","dir":"Articles","previous_headings":"","what":"The Theory","title":"hmde for Mathematicians","text":"underlying method hmde package implements leverages longitudinal structure repeat measurement data estimate parameters underlying differential equation, first demonstrated . method example Bayesian inverse method differential equation estimation: attempting estimate parameters chosen DE based observations resulting process. assume data consists finite number discrete (likely sparse) observations measurement error individual level, set number possible differential equations ready fit data.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde_for_mathematicians.html","id":"the-maths","dir":"Articles","previous_headings":"The Theory","what":"The Maths","title":"hmde for Mathematicians","text":"general setting, interested quantity Y(t)Y(t) changes time (approximately) according chosen DE ff. finite finite number measurements times tjt_j, believe underlying true behaviour given Y(tj+1)=Y(tj)+‚à´tjtj+1f(Y(t),ùõâ)dt(1) Y(t_{j+1}) = Y(t_j) + \\int_{t_j}^{t_{j+1}} f(Y(t), \\boldsymbol{\\theta})\\,dt\\qquad (1)  unseen parameter vector ùõâ\\boldsymbol{\\theta} wish estimate. also initial condition Y0=Y(t0)Y_0 = Y(t_0). three -built growth functions hmde. Constant: f=Œ≤f = \\beta chosen two observations average growth rate best can . Furthermore, results constant model align linear mixed effects model size individual parameter. constant model size-independent. numerical methods equivalent analytic solution given initial condition, use Euler method constant model. von Bertalanffy: f=Œ≤(Ymax‚àíY(t))(2)f = \\beta (Y_{max} - Y(t))\\qquad\\qquad(2) history use biology species grow maximum size, represents simple size-dependent linear function. power law model desired, log-transforming observations back-transforming exponentiation gives function. Equation (2) implemented analytic solution rather numerical method, known nightmare example numerical stability due negative coefficient Y(t)Y(t). Canham: f=fmaxexp(‚àí12(log(Y(t)/Ymax)k)2),(3) f = f_{max} \\exp\\Bigg(-\\frac{1}{2}\\bigg(\\frac{\\log(Y(t)/Y_{max})}{k} \\bigg)^2 \\Bigg),\\qquad\\qquad(3)  considered reasonable approximation long term growth behaviour tree species shown [Chapter 2]. Equation (3) extremely non-linear analytic solution, forcing use numerical methods order estimate growth increments Equation (1). Affine: f=Œ≤0‚àíŒ≤1Y(t)f = \\beta_0 - \\beta_1 Y(t) included demonstration purposes numerical methods can go wrong re-parameterisation von Bertalanffy model. Choice appropriate function exercise user depends available data. Aside affine model versions work single individual, multiple individuals. provide example data intended use primary models: - Trout_Size_Data constant model, - Lizard_Size_Data von Bertalanffy model, - Tree_Size_Data Canham model.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde_for_mathematicians.html","id":"the-stats","dir":"Articles","previous_headings":"The Theory","what":"The Stats","title":"hmde for Mathematicians","text":"assume access ùõâ\\boldsymbol{\\theta} true values YY time. Instead observations measurement error, yj=Y(tj)+error, y_j = Y(t_j) + \\text{error},  estimate ùõâ\\boldsymbol{\\theta} ùõâÃÇ\\hat{\\boldsymbol{\\theta}}. use hierarchical structure encode different levels relationships within data. bottom hierarchy measurement level yj‚àºùí©(YÃÇ(tj),œÉe), y_j \\sim \\mathcal{N}(\\hat{Y}(t_j), \\sigma_e),  assume normally distributed error. may always true, indicated symmetric error centred 0 may enough reasonable results. longitudinal structure Equation (1) serves next level, connecting estimated sizes time based chosen function ff estimated parameters ùõâÃÇ\\hat{\\boldsymbol{\\theta}}, operates level individual. data multiple individuals add additional layers act hyper-parameters distributions elements individual ii‚Äôs ùõâÃÇ\\hat{\\boldsymbol{\\theta}}_i. build independent Œ∏ki\\theta_{ki}s, log-mean log-standard deviation parameters Œ∏k‚àºlogùí©(Œºk,œÉk), \\theta_k \\sim \\log\\mathcal{N}(\\mu_k, \\sigma_k),  typically use following priors: Œºk‚àºùí©(0,2),0<œÉk‚àºCauchy(0,2). \\mu_k \\sim\\mathcal{N}(0,2), \\quad 0 < \\sigma_k\\sim Cauchy(0, 2).  details prior distributions see vignette specific model check Stan file. see default values run hmde_model model name string look prior_pars argument parameter name: error parameter œÉe>0\\sigma_e >0 assumed operate global level independent individual typically Cauchy prior location 0, spread parameter 2. Estimation done using MCMC Stan.","code":"hmde_model(\"canham_multi_ind\") #> [1] \"Model: canham_multi_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $n_ind #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $ind_id #> NULL #>  #> $prior_pars_pop_log_max_growth_mean #> [1] 0 2 #>  #> $prior_pars_pop_log_max_growth_sd #> [1] 0 2 #>  #> $prior_pars_pop_log_size_at_max_growth_mean #> [1] 0 2 #>  #> $prior_pars_pop_log_size_at_max_growth_sd #> [1] 0 2 #>  #> $prior_pars_pop_log_k_mean #> [1] 0 2 #>  #> $prior_pars_pop_log_k_sd #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"canham_multi_ind\""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde_for_mathematicians.html","id":"integration-of-time-series","dir":"Articles","previous_headings":"The Theory","what":"Integration of time series","title":"hmde for Mathematicians","text":"Numerical methods required Canham model analytic solution, inbuilt Stan Runge-Kutta 4-5 solver used. von Bertalanffy model analytic solution used order avoid numerical problems. constant model numerical methods give result analytic solution Euler used.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/hmde_for_mathematicians.html","id":"demonstration-canham-growth---multiple-individuals","dir":"Articles","previous_headings":"","what":"Demonstration: Canham Growth - Multiple Individuals","title":"hmde for Mathematicians","text":"provided tree data 50 individuals takes hours run. , following block run default, instead leverage provided estimates data file: Tree_Size_Ests. estimates posterior mean, median, 95% central credible intervals parameters, mean posterior estimates sizes time based longitudinal model. following code produces plots Canham function individual first last estimated size. purpose plot look different individual growth functions behave. line represents 25 years growth specific individual. Lines sit lower yy-axis shorter horizontally traversed slowly, ff rate change YY. understand error model, following code plots number individual sizes time, super-imposes growth curves black individual growth function plots. view specific individual, use ind_id value select .","code":"# Build fit and extract estimates canham_multi_ind_fit <- hmde_model(\"canham_multi_ind\") |>   hmde_assign_data(data = Tree_Size_Data)  |>   hmde_run(chains = 1, cores = 1, iter = 1000)  Tree_Size_Ests <- hmde_extract_estimates(fit = canham_multi_ind_fit,                                  input_measurement_data = Tree_Size_Data) summary(Tree_Size_Ests) #>                  Length Class  Mode      #> model_name        1     -none- character #> measurement_data  5     tbl_df list      #> individual_data  13     tbl_df list      #> error_data        5     tbl_df list      #> population_data   5     tbl_df list  # Plot fitted growth function pieces plot_par_individual_data <- Tree_Size_Ests$individual_data[,c(1, 2, 6, 10)] #Pull out estimates only hmde_plot_de_pieces(Tree_Size_Ests) #Plots of size over time for a sample of 5 individuals sample_ids <- sample(1:nrow(Tree_Size_Ests$individual_data), size=5) %>%   sort() plot_data <- Tree_Size_Ests$measurement_data %>%   filter(ind_id %in% sample_ids)  ind_size_lims <- Tree_Size_Ests$measurement_data %>%   filter(ind_id %in% sample_ids)%>%   group_by(ind_id) %>%   summarise(y_0 = min(y_hat),          y_final = max(y_hat))  ggplot(data=plot_data, aes(group = ind_id)) +   geom_point(aes(x = time, y=y_obs, colour = as.factor(ind_id)),              shape = 1) +   geom_line(aes(x = time, y=y_obs, colour = as.factor(ind_id)),             linetype = \"dashed\") +   geom_point(aes(x = time, y=y_hat, colour = as.factor(ind_id)),              shape = 2) +   geom_line(aes(x = time, y=y_hat, colour = as.factor(ind_id)),             linetype = \"solid\") +   labs(x=\"Time (years)\", y=\"DBH (cm)\", colour=\"Ind. ID\") +   theme_classic() #Load DE for Canham DE_function = hmde_model_des(\"canham_multi_ind\")  #Produce plot with focus inds function_plot <- hmde_plot_de_pieces(Tree_Size_Ests,                     alpha = 0.2)  for(i in 1:length(sample_ids)){   args_list <- list(pars=Tree_Size_Ests$individual_data[sample_ids[i],c(2, 6, 10)])      function_plot <- function_plot +       geom_function(fun=DE_function, args=args_list,                     colour=\"black\", linewidth=1, alpha = 1,                     xlim=c(ind_size_lims$y_0[i], ind_size_lims$y_final[i]))      }  function_plot"},{"path":"https://traitecoevo.github.io/hmde/articles/von-bertalanffy.html","id":"load-dependencies","dir":"Articles","previous_headings":"","what":"Load dependencies","title":"Case study 2: von Bertalanffy growth with lizard size data","text":"","code":"# remotes::install_github(\"traitecoevo/hmde\") # install.packages(c(\"dplyr\", \"ggplot2\"))  library(hmde) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://traitecoevo.github.io/hmde/articles/von-bertalanffy.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Case study 2: von Bertalanffy growth with lizard size data","text":"second demo introduces size-dependent growth based von Bertalanffy function f(Y(t);Smax,Œ≤)=Œ≤(Smax‚àíY(t)),\\begin{equation}\\label{eqn_vb_DE} f(Y(t); S_{max}, \\beta) = \\beta(S_{max} - Y(t)), \\end{equation} SmaxS_{max} asymptotic maximum size Œ≤\\beta controls growth rate. implemented analytic solution Y(t)=Smax+(Y(0)‚àíSmax)exp(‚àítŒ≤)\\begin{equation}\\label{eqn_vb_soln} Y(t) = S_{max} + (Y(0) - S_{max}) \\exp(-t\\beta) \\end{equation} independent age starting size Y(0)Y(0) instead uses first size initial condition. key behaviour von Bertalanffy model high growth rate small sizes declines linearly size approaches SmaxS_{max}. manifests growth slowing creature matures hard finite limit eventual size. restrict Œ≤\\beta SmaxS_{max} positive. result growth rate non-negative.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/von-bertalanffy.html","id":"priors","dir":"Articles","previous_headings":"Overview","what":"Priors","title":"Case study 2: von Bertalanffy growth with lizard size data","text":"default priors constant top-level parameters single individual model Smax‚àºlogùí©(log(max(yobs)),2),S_{max} \\sim \\log\\mathcal{N}(\\log(\\max(y_{obs})), 2),Œ≤‚àºlogùí©(0,2),\\beta \\sim \\log\\mathcal{N}(0, 2),0<œÉe‚àºCauchy(0,2).0 <\\sigma_e \\sim Cauchy(0, 2). multi-individual model prior structure default parameters ŒºSmax‚àºùí©(log(max(yobs)),2),\\mu_{S_{max}} \\sim \\mathcal{N}(\\log(\\max(y_{obs})), 2),0<œÉSmax‚àºCauchy(0,2),0 < \\sigma_{S_{max}} \\sim Cauchy(0, 2),ŒºŒ≤‚àºùí©(0,2),\\mu_{\\beta} \\sim \\mathcal{N}(0, 2),0<œÉŒ≤‚àºCauchy(0,2),0 < \\sigma_{\\beta} \\sim Cauchy(0, 2),0<œÉe‚àºCauchy(0,2).0 < \\sigma_{e} \\sim Cauchy(0, 2). max size parameter priors always centred (transformed) maximum observed size. changeable, standard deviation . see name prior parameter run hmde_model. example following want change prior SmaxS_{max} standard deviation (ind_max_size) individual model:","code":"hmde_model(\"vb_single_ind\") #> [1] \"Model: vb_single_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $y_bar #> NULL #>  #> $prior_pars_ind_max_size_sd_only #> [1] 2 #>  #> $prior_pars_ind_growth_rate #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"vb_single_ind\" #prior_pars_ind_max_size_sd_only is the argument name for the prior parameter"},{"path":"https://traitecoevo.github.io/hmde/articles/von-bertalanffy.html","id":"visualise-model","dir":"Articles","previous_headings":"Overview","what":"Visualise model","title":"Case study 2: von Bertalanffy growth with lizard size data","text":"following code plot example growth function solution get feel behaviour.   von Bertalanffy model commonly used fishery management (Flinn Midway 2021), also used reptile studies Edmonds et al. (2021) Zhao et al. (2020).","code":"#Analytic solution in function form solution <- function(t, pars = list(y_0, beta, S_max)){   return(     pars$S_max + (y_0 - pars$S_max)*exp(-t * pars$beta)   ) }  #Parameters beta <- 0.35 #Growth rate y_0 <- 1 #Starting size S_max <- 20 #Asymptotic max size time <- c(0,30)  pars_list <- list(y_0 = y_0,                   beta = beta,                   S_max = S_max) y_final <- solution(time[2], pars_list)  #Plot of growth function ggplot() +   xlim(y_0, y_final) +   ylim(0, beta*(S_max-y_0)*1.1) +   labs(x = \"Y(t)\", y = \"f\", title = \"von Berralanffy growth\") +   theme_classic() +   theme(axis.text=element_text(size=16),         axis.title=element_text(size=18,face=\"bold\")) +   geom_function(fun=hmde_model_des(\"vb_single_ind\"),                  args=list(pars = list(S_max, beta)),                 colour=\"green4\", linewidth=1,                 xlim=c(y_0, y_final)) #Size over time ggplot() +   geom_function(fun=solution,                  args=list(pars = pars_list),                 colour=\"green4\", linewidth=1,                 xlim=c(time)) +   xlim(time) +   ylim(0, y_final*1.05) +   labs(x = \"Time\", y = \"Y(t)\", title = \"von Bertalanffy growth\") +   theme_classic() +   theme(axis.text=element_text(size=16),         axis.title=element_text(size=18,face=\"bold\"))"},{"path":"https://traitecoevo.github.io/hmde/articles/von-bertalanffy.html","id":"lizard-size-data","dir":"Articles","previous_headings":"","what":"Lizard size data","title":"Case study 2: von Bertalanffy growth with lizard size data","text":"data sourced Kar, Nakagawa, Noble (2023) measured mass snout-vent-length (SVL) delicate skinks ‚Äì ‚Äì experimental conditions examine effect temperature development. going use SVL metric size. took simple random sample without replacement 50 individuals least 5 observations . von Bertalanffy model can fit shorter observation lengths, fewer 3 observations advised two growth parameters per individual.","code":""},{"path":"https://traitecoevo.github.io/hmde/articles/von-bertalanffy.html","id":"implementation","dir":"Articles","previous_headings":"","what":"Implementation","title":"Case study 2: von Bertalanffy growth with lizard size data","text":"workflow second example first, change model name data object. , can compare observed sizes time predicted model.    two parameters individual level interested separate distributions, see evidence relationship . can also use individual parameter estimates estimated sizes plot growth function pieces. hyper-parameter level whole population centre spread parameters log-normal distributions SmaxS_{max} Œ≤\\beta. , can look species-level features.","code":"lizard_vb_fit <- hmde_model(\"vb_multi_ind\") |>   hmde_assign_data(data = Lizard_Size_Data)  |>   hmde_run(chains = 4, cores = 1, iter = 2000) #>  #> SAMPLING FOR MODEL 'vb_multi_ind' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.00012 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.2 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 5.474 seconds (Warm-up) #> Chain 1:                4.242 seconds (Sampling) #> Chain 1:                9.716 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'vb_multi_ind' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 6.4e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.64 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 3.002 seconds (Warm-up) #> Chain 2:                1.648 seconds (Sampling) #> Chain 2:                4.65 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'vb_multi_ind' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 6e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.6 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 5.524 seconds (Warm-up) #> Chain 3:                6.66 seconds (Sampling) #> Chain 3:                12.184 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'vb_multi_ind' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 5.5e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.55 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 10.255 seconds (Warm-up) #> Chain 4:                3.307 seconds (Sampling) #> Chain 4:                13.562 seconds (Total) #> Chain 4: #> Warning: There were 122 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: There were 4 chains where the estimated Bayesian Fraction of Missing Information was low. See #> https://mc-stan.org/misc/warnings.html#bfmi-low #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  lizard_estimates <- hmde_extract_estimates(fit = lizard_vb_fit,                                            input_measurement_data = Lizard_Size_Data) measurement_data_transformed <- lizard_estimates$measurement_data %>%   group_by(ind_id) %>%   mutate(     delta_y_obs = y_obs - lag(y_obs),     obs_interval = time - lag(time),     obs_growth_rate = delta_y_obs/obs_interval,     delta_y_est = y_hat - lag(y_hat),     est_growth_rate = delta_y_est/obs_interval   ) %>%   ungroup()   #Distributions of estimated growth and size hist(measurement_data_transformed$y_hat,       main = \"Estimated size distribution\",      xlab = \"Size (cm)\") hist(measurement_data_transformed$delta_y_est,       main = \"Estimated growth increments\",      xlab = \"Growth increment (cm)\") hist(measurement_data_transformed$est_growth_rate,       main = \"Estimated annualised growth rate distribution\",      xlab = \"Growth rate (cm/yr)\") #Quantitative R^2 cor(measurement_data_transformed$y_obs, measurement_data_transformed$y_hat)^2 #> [1] 0.7416779 r_sq_est <- cor(lizard_estimates$measurement_data$y_obs,                 lizard_estimates$measurement_data$y_hat)^2 r_sq <- paste0(\"R^2 = \",                 signif(r_sq_est,                       digits = 3))  obs_scatter <- ggplot(data = lizard_estimates$measurement_data,         aes(x = y_obs, y = y_hat)) +   geom_point(shape = 16, size = 1, colour = \"green4\") +   xlab(\"Y obs.\") +   ylab(\"Y est.\") +   geom_abline(slope = 1, linetype = \"dashed\") +   annotate(\"text\", x = 25, y = 18,             label = r_sq) +   theme_classic()  #Plots of size over time for a sample of 5 individuals obs_est_ind <- hmde_plot_obs_est_inds(n_ind_to_plot = 5,                        measurement_data = lizard_estimates$measurement_data) +   theme(legend.position = \"inside\",         legend.position.inside = c(0.8, 0.2)) #1-dimensional parameter distributions s_max_hist <- ggplot(lizard_estimates$individual_data,         aes(ind_max_size_mean)) +   geom_histogram(bins = 10,                  colour = \"black\",                  fill = \"lightblue\") +   labs(x=\"S_max estimate\") +   theme_classic()  beta_hist <- ggplot(lizard_estimates$individual_data,         aes(ind_growth_rate_mean)) +   geom_histogram(bins = 10,                  colour = \"black\",                  fill = \"lightblue\") +   labs(x=\"beta estimate\") +   theme_classic()  #2-dimensional parameter distribution par_scatter <- ggplot(data = lizard_estimates$individual_data,         aes(x = ind_max_size_mean, y = ind_growth_rate_mean)) +   geom_point(shape = 16, size = 1, colour = \"green4\") +   xlab(\"Individual max sizes (mm)\") +   ylab(\"Individual growth rate parameters\") +   theme_classic()  #Correlation of parameters cor(lizard_estimates$individual_data$ind_max_size_mean,     lizard_estimates$individual_data$ind_growth_rate_mean,     method = \"spearman\") #> [1] 0.5702281  #Plot function pieces over estimated sizes. de_pieces <- hmde_plot_de_pieces(lizard_estimates) pars_CI_names <- c(   \"mean log max size\",   \"mean max size in mm\",   \"log max size standard deviation\",   \"mean log growth par\",   \"mean growth par mm/yr\",   \"log growth par standard deviation\" )  #Vector that picks out which pars to be exponentiated exp_vec <- c(FALSE, TRUE, FALSE,               FALSE, TRUE, FALSE)  #Print mean estimates and CIs for(i in 1:nrow(lizard_estimates$population_data)){   if(!exp_vec[i]){     lizard_estimates$population_data$mean[i]      print(paste0(\"95% CI for \",                   pars_CI_names[i],                  \": (\",                  lizard_estimates$population_data$CI_lower[i],                  \", \",                  lizard_estimates$population_data$CI_upper[i],                  \")\"))   } else {     exp(lizard_estimates$population_data$mean[i])     print(paste0(\"95% CI for \",                  pars_CI_names[i],                   \": (\",                  exp(lizard_estimates$population_data$CI_lower[i]),                  \", \",                  exp(lizard_estimates$population_data$CI_upper[i]),                  \")\"))   } } #> [1] \"95% CI for mean log max size: (3.17647083072528, 3.21407083090968)\" #> [1] \"95% CI for mean max size in mm: (1.01045823319106, 1.04954895929649)\" #> [1] \"95% CI for log max size standard deviation: (-4.14301908332485, -3.75812194862982)\" #> [1] \"95% CI for mean log growth par: (0.0233751801356016, 0.237118800131887)\""},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Falster. Author, contributor. Tess O'Brien. Author, maintainer, copyright holder. Fonti Kar. Contributor. David Warton. Author, contributor.","code":""},{"path":"https://traitecoevo.github.io/hmde/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Falster D, O'Brien T, Warton D (2025). hmde: Hierarchical Methods Differential Equations. R package version 1.3.1, https://traitecoevo.github.io/hmde/.","code":"@Manual{,   title = {hmde: Hierarchical Methods for Differential Equations},   author = {Daniel Falster and Tess O'Brien and David Warton},   year = {2025},   note = {R package version 1.3.1},   url = {https://traitecoevo.github.io/hmde/}, }"},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"hmde-","dir":"","previous_headings":"","what":"Hierarchical Methods for Differential Equations","title":"Hierarchical Methods for Differential Equations","text":"goal hmde fit model rate change quantity based set pre-defined functions arising ecological applications. estimate differential equation parameters repeated observations process, growth rate parameters data sizes time. language, hmde implements hierarchical Bayesian longitudinal models solve Bayesian inverse problem estimating differential equation parameters based repeat measurement surveys. Estimation done using Markov Chain Monte Carlo, implemented Stan via RStan, built R 4.3.3. inbuilt models based case studies ecology. pre-print paper available bioarXiv, hmde_paper.pdf file .","code":""},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"the-maths","dir":"","previous_headings":"","what":"The Maths","title":"Hierarchical Methods for Differential Equations","text":"general use case estimate vector parameters Œ∏\\theta chosen differential equation f(Y(t),Œ∏)=dYdtf\\left( Y \\left( t \\right), \\theta \\right) = \\frac{dY}{dt} based longitudinal structure Y(tj+1)=Y(tj)+‚à´tjtj+1f(Y(t),Œ∏)dt.Y \\left( t_{j+1} \\right) = Y\\left( t_j \\right) + \\int_{t_j}^{t_{j+1}}f\\left( Y \\left( t \\right), \\theta \\right)\\,dt. input data observations form yijy_{ij} individual ii time tjt_j, repeated observations coming individual. parameterise ff individual level estimating Œ∏i\\theta_i vector parameters. hyper-parameters determine distribution Œ∏i\\theta_i typical prior distribution Œ∏i‚àºlogùí©(Œºlog(Œ∏),œÉlog(Œ∏)),\\theta_i \\sim \\log \\mathcal{N}\\left(\\mu_{\\log\\left(\\theta\\right)}, \\sigma_{\\log \\left( \\theta \\right)}\\right),  Œºlog(Œ∏)\\mu_{\\log\\left(\\theta\\right)} œÉlog(Œ∏)\\sigma_{\\log\\left(\\theta\\right)} vectors means standard deviations. case single individual, chosen prior values. case multi-individual model Œºlog(Œ∏)\\mu_{\\log\\left(\\theta\\right)} œÉlog(Œ∏)\\sigma_{\\log\\left(\\theta\\right)} prior distributions fit data.","code":""},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"implemented-models","dir":"","previous_headings":"","what":"Implemented Models","title":"Hierarchical Methods for Differential Equations","text":"hmde comes four DEs built ready go, version single individual multiple individuals.","code":""},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"constant-model","dir":"","previous_headings":"Implemented Models","what":"Constant Model","title":"Hierarchical Methods for Differential Equations","text":"constant model given f(Y(t),Œ≤)=dYdt=Œ≤,f \\left( Y \\left( t \\right), \\beta \\right) = \\frac{dY}{dt} = \\beta, best understood describing average rate change time.","code":""},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"von-bertalanffy","dir":"","previous_headings":"Implemented Models","what":"von Bertalanffy","title":"Hierarchical Methods for Differential Equations","text":"von Bertalanffy mode given f(Y(t),Œ≤,Ymax)=dYdt=Œ≤(Ymax‚àíY(t)),f \\left( Y \\left( t \\right), \\beta, Y_{max} \\right) = \\frac{dY}{dt} = \\beta \\left( Y_{max} - Y \\left( t \\right) \\right), Œ≤\\beta growth rate parameter YmaxY_{max} maximum value YY takes.","code":""},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"canham","dir":"","previous_headings":"Implemented Models","what":"Canham","title":"Hierarchical Methods for Differential Equations","text":"Canham (Canham et al.¬†2004) model hump-shaped function given f(Y(t),fmax,Ymax,k)=dYdt=fmaxexp(‚àí12(ln(Y(t)/Ymax)k)2),f \\left( Y \\left( t \\right), f_{max}, Y_{max}, k \\right) = \\frac{dY}{dt} = f_{max} \\exp \\Bigg( -\\frac{1}{2} \\bigg( \\frac{ \\ln \\left( Y \\left( t \\right) / Y_{max} \\right) }{k} \\bigg)^2 \\Bigg),  fmaxf_{max} maximum growth rate, YmaxY_{max} YY-value maximum occurs, kk controls narrow wide peak .","code":""},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Hierarchical Methods for Differential Equations","text":"‚Äòhmde‚Äô active development. can install current developmental version ‚Äòhmde‚Äô GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"traitecoevo/hmde\")"},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"quick-demo","dir":"","previous_headings":"","what":"Quick demo","title":"Hierarchical Methods for Differential Equations","text":"Create constant growth data measurement error: Measurement error necessary otherwise normal likelihood sij‚àºùí©(0,œÉe)s_{ij} \\sim \\mathcal{N}\\left( 0, \\sigma_e \\right) blows œÉe\\sigma_e approaches 0. Fit model:","code":"library(hmde) y_obs <- seq(from=2, to=15, length.out=10) + rnorm(10, 0, 0.1) constant_fit <- hmde_model(\"constant_single_ind\") |>         hmde_assign_data(n_obs = 10,                  #Integer                          y_obs = y_obs,               #vector length n_obs                          obs_index = 1:10,            #vector length n_obs                          time = 0:9,                  #Vector length n_obs                          y_0_obs = y_obs[1]           #Real         ) |>         hmde_run(chains = 1, iter = 1000, verbose = FALSE, show_messages = FALSE)"},{"path":"https://traitecoevo.github.io/hmde/index.html","id":"found-a-bug","dir":"","previous_headings":"","what":"Found a bug?","title":"Hierarchical Methods for Differential Equations","text":"Please submit GitHub issue details bug. reprex particularly helpful bug-proofing process!","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Lizard_Size_Data.html","id":null,"dir":"Reference","previous_headings":"","what":"Skink size data - Lampropholis delicata ‚Äî Lizard_Size_Data","title":"Skink size data - Lampropholis delicata ‚Äî Lizard_Size_Data","text":"subset data Kar, Nakagawa, Noble (2024), used model growth behaviour skink species. Observations length tip nose start cloaca. Data prepared taking simple random sample replacement 50 individual IDs among individuals least 5 observations . Data transformed conform needs model data set package.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Lizard_Size_Data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Skink size data - Lampropholis delicata ‚Äî Lizard_Size_Data","text":"","code":"Lizard_Size_Data"},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/reference/Lizard_Size_Data.html","id":"lizard-size-data","dir":"Reference","previous_headings":"","what":"Lizard_Size_Data","title":"Skink size data - Lampropholis delicata ‚Äî Lizard_Size_Data","text":"data frame 336 rows 4 columns: ind_id ID number individual time Days since first observation. y_obs Individual size mm. obs_index Index observations individual","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Lizard_Size_Data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Skink size data - Lampropholis delicata ‚Äî Lizard_Size_Data","text":"https://osf.io/hjkxd/","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Data.html","id":null,"dir":"Reference","previous_headings":"","what":"Garcinia recondita - Barro Colorado Island data ‚Äî Tree_Size_Data","title":"Garcinia recondita - Barro Colorado Island data ‚Äî Tree_Size_Data","text":"subset data Barro Colorado Island long term forest plot managed Smithsonian Tropical Research Institute (Condit et al. 2019). Data prepared taking simple random sample without replacement 30 individual IDs Garcinia recondita. sampling frame restricted individuals 6 observations since 1990, difference observed first last sizes 3cm order avoid identifiability issues. Data transformed renamed match required structure act demonstration package.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Garcinia recondita - Barro Colorado Island data ‚Äî Tree_Size_Data","text":"","code":"Tree_Size_Data"},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Data.html","id":"tree-size-data","dir":"Reference","previous_headings":"","what":"Tree_Size_Data","title":"Garcinia recondita - Barro Colorado Island data ‚Äî Tree_Size_Data","text":"data frame 300 rows 4 columns: ind_id ID number individual time Years since first observation. y_obs Individual diameter breast height (DBH) centimetres. obs_index Index observations individual","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Garcinia recondita - Barro Colorado Island data ‚Äî Tree_Size_Data","text":"doi:10.15146/5xcp-0d46","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Garcinia recondita - Barro Colorado Island data ‚Äî Tree_Size_Data","text":"doi:10.1002/ecy.4140","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Ests.html","id":null,"dir":"Reference","previous_headings":"","what":"Garcinia recondita model estimates - Barro Colorado Island data ‚Äî Tree_Size_Ests","title":"Garcinia recondita model estimates - Barro Colorado Island data ‚Äî Tree_Size_Ests","text":"Estimated sizes, individual growth parameters, population-level hyper-parameters Garcinia recondita fit Canham growth function hierarchical model. data used fit model Tree_Size_Data object.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Ests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Garcinia recondita model estimates - Barro Colorado Island data ‚Äî Tree_Size_Ests","text":"","code":"Tree_Size_Ests"},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/reference/Tree_Size_Ests.html","id":"tree-size-ests","dir":"Reference","previous_headings":"","what":"Tree_Size_Ests","title":"Garcinia recondita model estimates - Barro Colorado Island data ‚Äî Tree_Size_Ests","text":"list 5 elements: model character string giving model name - Canham multiple individuals. measurement_data tibble 5 columns gives information size observations estimates. individual_data tibble 13 columns gives posterior estimates individual growth parameters. error_data tibble 5 columns gives posterior estimates error parameter. population_data tibble 5 columns gives posterior estimates population-level hyper-parameters.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Trout_Size_Data.html","id":null,"dir":"Reference","previous_headings":"","what":"SUSTAIN Salmo trutta data ‚Äî Trout_Size_Data","title":"SUSTAIN Salmo trutta data ‚Äî Trout_Size_Data","text":"subset data SUSTAIN trout capture-recapture data set Moe et al. (2020). Observations total body length centimetres. Data prepared taking stratified sample individual IDs based number observations per individual: 25 individuals 2 observations, 15 3, 10 4. Within groups simple random sample without replacement used. Data transformed renamed match required structure act demonstration package.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Trout_Size_Data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SUSTAIN Salmo trutta data ‚Äî Trout_Size_Data","text":"","code":"Trout_Size_Data"},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/reference/Trout_Size_Data.html","id":"trout-size-data","dir":"Reference","previous_headings":"","what":"Trout_Size_Data","title":"SUSTAIN Salmo trutta data ‚Äî Trout_Size_Data","text":"data frame 135 rows 4 columns: ind_id ID number individual time Years since first capture tagging individual. y_obs Individual length centimetres. obs_index Index observations individual","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/Trout_Size_Data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"SUSTAIN Salmo trutta data ‚Äî Trout_Size_Data","text":"doi:10.3897/BDJ.8.e52157","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde-package.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'hmde' package. ‚Äî hmde-package","title":"The 'hmde' package. ‚Äî hmde-package","text":"package implement selection hierarchical Bayesian longitudinal models inverse Bayesian problems.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The 'hmde' package. ‚Äî hmde-package","text":"Stan Development Team (NA). RStan: R interface Stan. R package version 2.26.23. https://mc-stan.org","code":""},{"path":[]},{"path":"https://traitecoevo.github.io/hmde/reference/hmde-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The 'hmde' package. ‚Äî hmde-package","text":"Maintainer: Tess O'Brien tess_obrien@fastmail.com (ORCID) [copyright holder] Authors: Daniel Falster daniel.falster@unsw.edu.au (ORCID) [contributor] David Warton david.warton@unsw.edu.au (ORCID) [contributor] contributors: Fonti Kar f.kar@unsw.edu.au (ORCID) [contributor]","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_affine_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential equation for affine growth single individual model ‚Äî hmde_affine_de","title":"Differential equation for affine growth single individual model ‚Äî hmde_affine_de","text":"Differential equation affine growth single individual model","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_affine_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential equation for affine growth single individual model ‚Äî hmde_affine_de","text":"","code":"hmde_affine_de(y = NULL, pars = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_affine_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential equation for affine growth single individual model ‚Äî hmde_affine_de","text":"y input real pars list parameters beta_0, beta_1","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_affine_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential equation for affine growth single individual model ‚Äî hmde_affine_de","text":"value differential equation y","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_assign_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign data to template for chosen model ‚Äî hmde_assign_data","title":"Assign data to template for chosen model ‚Äî hmde_assign_data","text":"Assign data template chosen model","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_assign_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign data to template for chosen model ‚Äî hmde_assign_data","text":"","code":"hmde_assign_data(model_template, data = NULL, ...)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_assign_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign data to template for chosen model ‚Äî hmde_assign_data","text":"model_template output hmde_model data Input data tibble columns including time, y_obs, obs_index, additionally ind_id multi-individual models ... data-masking name-value pairs allowing specific input elements","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_assign_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign data to template for chosen model ‚Äî hmde_assign_data","text":"updated named list data assigned Stan model parameters","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_assign_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign data to template for chosen model ‚Äî hmde_assign_data","text":"","code":"# basic usage of hmde_assign_data hmde_model(\"constant_single_ind\") |> hmde_assign_data(Trout_Size_Data) #> [1] \"Model: constant_single_ind\" #> [1] \"Input data template:\" #> $n_obs #> [1] 135 #>  #> $y_obs #>   [1] 52 60 70 80 80 85 93 94 52 65 76 80 68 68 60 72 79 83 42 43 40 38 66 77 53 #>  [26] 61 83 87 86 81 79 68 77 58 69 76 74 87 90 78 87 83 64 70 74 51 59 65 59 66 #>  [51] 62 78 67 63 75 74 53 66 57 35 69 68 55 80 61 71 53 58 64 65 66 71 69 75 79 #>  [76] 64 66 61 61 57 59 84 85 62 64 71 75 76 78 40 42 65 73 81 86 64 74 82 78 88 #> [101] 88 70 79 85 89 62 79 66 72 71 76 82 84 74 84 95 75 80 85 87 88 77 79 80 81 #> [126] 86 90 90 62 73 82 83 67 84 89 #>  #> $obs_index #>   [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 1 2 3 4 1 2 1 2 1 2 1 2 1 2 3 1 2 1 2 1 2 3 4 #>  [38] 1 2 1 2 3 1 2 3 1 2 3 1 2 1 2 3 1 2 3 1 2 1 2 1 2 1 2 1 2 1 2 3 4 1 2 3 1 #>  [75] 2 1 2 1 2 1 2 1 2 1 2 1 2 3 4 1 2 1 2 1 2 1 2 3 1 2 3 1 2 3 4 1 2 1 2 3 1 #> [112] 2 3 1 2 3 1 2 1 2 3 1 2 3 1 2 3 4 1 2 3 4 1 2 3 #>  #> $time #>   [1] 0.000000000 1.913757700 4.019164956 6.036960986 0.000000000 1.897330595 #>   [7] 3.937029432 5.963039014 0.000000000 2.026009582 4.232717317 5.420944559 #>  [13] 0.000000000 0.793976728 0.000000000 1.973990418 3.890485969 5.979466119 #>  [19] 0.000000000 0.851471595 0.000000000 0.002737851 0.000000000 1.754962355 #>  [25] 0.000000000 1.801505818 0.000000000 1.891854894 2.521560575 0.000000000 #>  [31] 0.741957563 0.000000000 2.047912389 0.000000000 2.031485284 4.005475702 #>  [37] 5.834360027 0.000000000 2.067077344 0.000000000 2.149212868 4.016427105 #>  [43] 0.000000000 1.889117043 4.068446270 0.000000000 2.004106776 3.742642026 #>  [49] 0.000000000 2.091718001 0.000000000 2.001368925 3.926078029 0.000000000 #>  [55] 2.009582478 2.015058179 0.000000000 4.054757016 0.000000000 2.047912389 #>  [61] 0.000000000 1.212867899 0.000000000 1.976728268 0.000000000 2.143737166 #>  [67] 0.000000000 1.853524983 3.901437372 4.925393566 0.000000000 2.132785763 #>  [73] 2.844626968 0.000000000 1.941136208 0.000000000 0.903490760 0.000000000 #>  [79] 0.917180014 0.000000000 0.848733744 0.000000000 2.759753593 0.000000000 #>  [85] 0.876112252 0.000000000 2.009582478 3.983572895 5.905544148 0.000000000 #>  [91] 1.670088980 0.000000000 0.818617385 0.000000000 3.299110198 0.000000000 #>  [97] 1.954825462 3.225188227 0.000000000 1.949349760 5.169062286 0.000000000 #> [103] 1.760438056 3.874058864 5.043121150 0.000000000 1.582477755 0.000000000 #> [109] 1.817932923 1.998631075 0.000000000 2.193018480 3.233401780 0.000000000 #> [115] 2.020533881 5.809719370 0.000000000 0.229979466 0.000000000 1.916495551 #> [121] 3.986310746 0.000000000 1.878165640 3.789185489 0.000000000 1.733059548 #> [127] 3.822039699 8.780287474 0.000000000 1.924709103 4.005475702 6.995208761 #> [133] 0.000000000 4.005475702 8.005475702 #>  #> $prior_pars_ind_beta #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_single_ind\" #>"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_canham_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential equation for Canham growth single and multi- individual models ‚Äî hmde_canham_de","title":"Differential equation for Canham growth single and multi- individual models ‚Äî hmde_canham_de","text":"Differential equation Canham growth single multi- individual models","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_canham_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential equation for Canham growth single and multi- individual models ‚Äî hmde_canham_de","text":"","code":"hmde_canham_de(y = NULL, pars = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_canham_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential equation for Canham growth single and multi- individual models ‚Äî hmde_canham_de","text":"y input real pars list parameters g_max, S_max, k","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_canham_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential equation for Canham growth single and multi- individual models ‚Äî hmde_canham_de","text":"value differential equation y","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_const_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential equation for constant growth single and multi- individual models ‚Äî hmde_const_de","title":"Differential equation for constant growth single and multi- individual models ‚Äî hmde_const_de","text":"Differential equation constant growth single multi- individual models","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_const_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential equation for constant growth single and multi- individual models ‚Äî hmde_const_de","text":"","code":"hmde_const_de(y = NULL, pars = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_const_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential equation for constant growth single and multi- individual models ‚Äî hmde_const_de","text":"y input real pars list parameter beta","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_const_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential equation for constant growth single and multi- individual models ‚Äî hmde_const_de","text":"value differential equation y","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_Rhat.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Rhat statistics for a hmde_fit object ‚Äî hmde_extract_Rhat","title":"Calculate Rhat statistics for a hmde_fit object ‚Äî hmde_extract_Rhat","text":"Calculate Rhat statistics hmde_fit object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_Rhat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Rhat statistics for a hmde_fit object ‚Äî hmde_extract_Rhat","text":"","code":"hmde_extract_Rhat(fit)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_Rhat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Rhat statistics for a hmde_fit object ‚Äî hmde_extract_Rhat","text":"fit hmde_fit fitted model object, output hmde_run","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_Rhat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Rhat statistics for a hmde_fit object ‚Äî hmde_extract_Rhat","text":"named vector Rhat values","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_Rhat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Rhat statistics for a hmde_fit object ‚Äî hmde_extract_Rhat","text":"","code":"# basic usage of hmde_extract_Rhat hmde_model(\"constant_single_ind\") |>   hmde_assign_data(Trout_Size_Data)|>   hmde_run(chains = 2, iter = 1000,            verbose = FALSE, show_messages = FALSE) |>   hmde_extract_Rhat() #>  #> SAMPLING FOR MODEL 'constant_single_ind' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.4e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.047 seconds (Warm-up) #> Chain 1:                0.032 seconds (Sampling) #> Chain 1:                0.079 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'constant_single_ind' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.05 seconds (Warm-up) #> Chain 2:                0.037 seconds (Sampling) #> Chain 2:                0.087 seconds (Total) #> Chain 2:  #>            ind_y_0           ind_beta global_error_sigma              y_hat  #>           1.017323           1.007018           1.002807           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.005895           1.008050           1.007499           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.005859           1.008361           1.007821           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.006209           1.009006           1.007800           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.009745           1.017323           1.006080           1.008257  #>              y_hat              y_hat              y_hat              y_hat  #>           1.007691           1.017323           1.008494           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017322           1.017323           1.005382           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.005514           1.017323           1.005836           1.007864  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.010454           1.017323           1.006283  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.006221           1.008183           1.007821  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.006346           1.017323           1.006637  #>              y_hat              y_hat              y_hat              y_hat  #>           1.008102           1.017323           1.005823           1.008282  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.006167           1.008432           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.006441           1.017323           1.006158           1.008318  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.006189           1.006197           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.008092           1.017323           1.006283           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.004826           1.017323           1.006085           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.006621           1.017323           1.005699           1.008221  #>              y_hat              y_hat              y_hat              y_hat  #>           1.008558           1.017323           1.006580           1.008335  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.005990           1.017323           1.007652  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.007452           1.017323           1.008625  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.008276           1.017323           1.008025  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.006189           1.008227           1.007931  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.005109           1.017323           1.009341  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.008482           1.017323           1.006025  #>              y_hat              y_hat              y_hat              y_hat  #>           1.008462           1.017323           1.006010           1.008573  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.005401           1.008257           1.008516  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.004876           1.017323           1.005573  #>              y_hat              y_hat              y_hat              y_hat  #>           1.006154           1.017323           1.006827           1.008469  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.006200           1.007897           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.014513           1.017323           1.005901           1.008204  #>              y_hat              y_hat              y_hat              y_hat  #>           1.017323           1.005791           1.008367           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.005295           1.008354           1.006391           1.017323  #>              y_hat              y_hat              y_hat              y_hat  #>           1.005934           1.008175           1.007081           1.017323  #>              y_hat              y_hat               lp__  #>           1.008183           1.007190           1.007485"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract samples and return measurement, individual, and population-level estimates ‚Äî hmde_extract_estimates","title":"Extract samples and return measurement, individual, and population-level estimates ‚Äî hmde_extract_estimates","text":"Extract samples return measurement, individual, population-level estimates","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract samples and return measurement, individual, and population-level estimates ‚Äî hmde_extract_estimates","text":"","code":"hmde_extract_estimates(fit = NULL, input_measurement_data = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract samples and return measurement, individual, and population-level estimates ‚Äî hmde_extract_estimates","text":"fit fitted model Stan fit input_measurement_data data used fit model ind_id, y_obs, time, obs_index tibble","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract samples and return measurement, individual, and population-level estimates ‚Äî hmde_extract_estimates","text":"named list data frames measurement, individual, population-level, error parameter estimates","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_extract_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract samples and return measurement, individual, and population-level estimates ‚Äî hmde_extract_estimates","text":"","code":"# basic usage of hmde_extract_estimates hmde_model(\"constant_single_ind\") |>   hmde_assign_data(Trout_Size_Data)|>   hmde_run(chains = 1, iter = 1000,            verbose = FALSE, show_messages = FALSE) |>   hmde_extract_estimates(Trout_Size_Data) #>  #> SAMPLING FOR MODEL 'constant_single_ind' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.043 seconds (Warm-up) #> Chain 1:                0.032 seconds (Sampling) #> Chain 1:                0.075 seconds (Total) #> Chain 1:  #> $model_name #> [1] \"constant_single_ind\" #>  #> $measurement_data #> # A tibble: 135 √ó 5 #>    ind_id  time y_obs obs_index y_hat #>     <dbl> <dbl> <dbl>     <dbl> <dbl> #>  1      1  0       52         1  65.9 #>  2      1  1.91    60         2  71.8 #>  3      1  4.02    70         3  78.4 #>  4      1  6.04    80         4  84.7 #>  5      2  0       80         1  65.9 #>  6      2  1.90    85         2  71.8 #>  7      2  3.94    93         3  78.1 #>  8      2  5.96    94         4  84.4 #>  9      3  0       52         1  65.9 #> 10      3  2.03    65         2  72.2 #> # ‚Ñπ 125 more rows #>  #> $individual_data #> # A tibble: 1 √ó 5 #>   ind_id ind_beta_mean ind_beta_median ind_beta_CI_lower ind_beta_CI_upper #>    <int>         <dbl>           <dbl>             <dbl>             <dbl> #> 1      1          3.11            3.11              2.25              3.99 #>  #> $error_data #> # A tibble: 1 √ó 5 #>   par_name            mean median CI_lower CI_upper #>   <chr>              <dbl>  <dbl>    <dbl>    <dbl> #> 1 global_error_sigma  11.1   11.1     9.96     12.3 #>"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Select data configuration template for hmde supported model ‚Äî hmde_model","title":"Select data configuration template for hmde supported model ‚Äî hmde_model","text":"Select data configuration template hmde supported model","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select data configuration template for hmde supported model ‚Äî hmde_model","text":"","code":"hmde_model(model = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select data configuration template for hmde supported model ‚Äî hmde_model","text":"model model name character string","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select data configuration template for hmde supported model ‚Äî hmde_model","text":"hmde_model_template class named list matches Stan model parameters","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select data configuration template for hmde supported model ‚Äî hmde_model","text":"","code":"# basic usage of hmde_model hmde_model(\"constant_single_ind\") #> [1] \"Model: constant_single_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $prior_pars_ind_beta #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_single_ind\" #>"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_des.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to select DE given model name ‚Äî hmde_model_des","title":"Function to select DE given model name ‚Äî hmde_model_des","text":"Function select DE given model name","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_des.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to select DE given model name ‚Äî hmde_model_des","text":"","code":"hmde_model_des(model = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_des.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to select DE given model name ‚Äî hmde_model_des","text":"model character string model name","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_des.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to select DE given model name ‚Äî hmde_model_des","text":"DE function corresponding specific model","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_des.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to select DE given model name ‚Äî hmde_model_des","text":"","code":"# basic usage of hmde_model_des hmde_model_des(\"constant_single_ind\") #> function (y = NULL, pars = NULL)  #> { #>     return(pars[[1]]) #> } #> <bytecode: 0x55c7064ff0d0> #> <environment: namespace:hmde>"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns names of available models. ‚Äî hmde_model_names","title":"Returns names of available models. ‚Äî hmde_model_names","text":"Returns names available models.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns names of available models. ‚Äî hmde_model_names","text":"","code":"hmde_model_names()"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns names of available models. ‚Äî hmde_model_names","text":"vector character strings model names.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns names of available models. ‚Äî hmde_model_names","text":"","code":"# basic usage of hmde_model_names hmde_model_names() #> [1] \"constant_single_ind\" \"constant_multi_ind\"  \"canham_single_ind\"   #> [4] \"canham_multi_ind\"    \"vb_single_ind\"       \"vb_multi_ind\"        #> [7] \"affine_single_ind\""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_pars.html","id":null,"dir":"Reference","previous_headings":"","what":"Show parameter list for hmde supported model ‚Äî hmde_model_pars","title":"Show parameter list for hmde supported model ‚Äî hmde_model_pars","text":"Show parameter list hmde supported model","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_pars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show parameter list for hmde supported model ‚Äî hmde_model_pars","text":"","code":"hmde_model_pars(model = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_pars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show parameter list for hmde supported model ‚Äî hmde_model_pars","text":"model model name character string","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_pars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show parameter list for hmde supported model ‚Äî hmde_model_pars","text":"named list matches Stan model parameters","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_model_pars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show parameter list for hmde supported model ‚Äî hmde_model_pars","text":"","code":"# basic usage of hmde_model_pars hmde_model_pars(\"constant_single_ind\") #> $measurement_pars_names #> [1] \"y_hat\" #>  #> $individual_pars_names #> [1] \"ind_beta\" #>  #> $error_pars_names #> [1] \"global_error_sigma\" #>  #> $model #> [1] \"constant_single_ind\" #>"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_Rhat_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot histogram of R_hat values for hmde_fit object. ‚Äî hmde_plot_Rhat_hist","title":"Plot histogram of R_hat values for hmde_fit object. ‚Äî hmde_plot_Rhat_hist","text":"Plot histogram R_hat values hmde_fit object.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_Rhat_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot histogram of R_hat values for hmde_fit object. ‚Äî hmde_plot_Rhat_hist","text":"","code":"hmde_plot_Rhat_hist(fit)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_Rhat_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot histogram of R_hat values for hmde_fit object. ‚Äî hmde_plot_Rhat_hist","text":"fit hmde_fit object output hmde_run","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_Rhat_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot histogram of R_hat values for hmde_fit object. ‚Äî hmde_plot_Rhat_hist","text":"ggplot object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_Rhat_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot histogram of R_hat values for hmde_fit object. ‚Äî hmde_plot_Rhat_hist","text":"","code":"# basic usage of hmde_plot_Rhat_hist hmde_model(\"constant_single_ind\") |>   hmde_assign_data(Trout_Size_Data)|>   hmde_run(chains = 2, iter = 1000,            verbose = FALSE, show_messages = FALSE) |>   hmde_plot_Rhat_hist() #>  #> SAMPLING FOR MODEL 'constant_single_ind' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.045 seconds (Warm-up) #> Chain 1:                0.032 seconds (Sampling) #> Chain 1:                0.077 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'constant_single_ind' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.8e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.046 seconds (Warm-up) #> Chain 2:                0.032 seconds (Sampling) #> Chain 2:                0.078 seconds (Total) #> Chain 2:  #> `stat_bin()` using `bins = 30`. Pick better value `binwidth`."},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_de_pieces.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot pieces of chosen differential equation model for each individual. Structured to take the individual data tibble that is built by the hmde_extract_estimates function using the ind_par_name_mean estimates. Function piece will go from the first fitted size to the last. Accepted ggplot arguments will change the axis labels, title, line colour, alpha ‚Äî hmde_plot_de_pieces","title":"Plot pieces of chosen differential equation model for each individual. Structured to take the individual data tibble that is built by the hmde_extract_estimates function using the ind_par_name_mean estimates. Function piece will go from the first fitted size to the last. Accepted ggplot arguments will change the axis labels, title, line colour, alpha ‚Äî hmde_plot_de_pieces","text":"Plot pieces chosen differential equation model individual. Structured take individual data tibble built hmde_extract_estimates function using ind_par_name_mean estimates. Function piece go first fitted size last. Accepted ggplot arguments change axis labels, title, line colour, alpha","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_de_pieces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot pieces of chosen differential equation model for each individual. Structured to take the individual data tibble that is built by the hmde_extract_estimates function using the ind_par_name_mean estimates. Function piece will go from the first fitted size to the last. Accepted ggplot arguments will change the axis labels, title, line colour, alpha ‚Äî hmde_plot_de_pieces","text":"","code":"hmde_plot_de_pieces(   estimate_list = NULL,   xlab = \"Y(t)\",   ylab = \"f\",   title = NULL,   colour = \"#006600\",   alpha = 0.4 )"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_de_pieces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot pieces of chosen differential equation model for each individual. Structured to take the individual data tibble that is built by the hmde_extract_estimates function using the ind_par_name_mean estimates. Function piece will go from the first fitted size to the last. Accepted ggplot arguments will change the axis labels, title, line colour, alpha ‚Äî hmde_plot_de_pieces","text":"estimate_list list output hmde_extract_estimates xlab character string replacement x axis label ylab character string replacement y axis label title character string replacement plot title colour character string replacement line colour alpha real number replacement alpha value","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_de_pieces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot pieces of chosen differential equation model for each individual. Structured to take the individual data tibble that is built by the hmde_extract_estimates function using the ind_par_name_mean estimates. Function piece will go from the first fitted size to the last. Accepted ggplot arguments will change the axis labels, title, line colour, alpha ‚Äî hmde_plot_de_pieces","text":"ggplot object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_de_pieces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot pieces of chosen differential equation model for each individual. Structured to take the individual data tibble that is built by the hmde_extract_estimates function using the ind_par_name_mean estimates. Function piece will go from the first fitted size to the last. Accepted ggplot arguments will change the axis labels, title, line colour, alpha ‚Äî hmde_plot_de_pieces","text":"","code":"# basic usage of hmde_plot_de_pieces hmde_plot_de_pieces(estimate_list = Tree_Size_Ests)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_obs_est_inds.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot estimated and observed values over time for a chosen number of individuals based on posterior estimates. Structured to take in the measurement_data tibble constructed by the hmde_extract_estimates function. ‚Äî hmde_plot_obs_est_inds","title":"Plot estimated and observed values over time for a chosen number of individuals based on posterior estimates. Structured to take in the measurement_data tibble constructed by the hmde_extract_estimates function. ‚Äî hmde_plot_obs_est_inds","text":"Plot estimated observed values time chosen number individuals based posterior estimates. Structured take measurement_data tibble constructed hmde_extract_estimates function.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_obs_est_inds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot estimated and observed values over time for a chosen number of individuals based on posterior estimates. Structured to take in the measurement_data tibble constructed by the hmde_extract_estimates function. ‚Äî hmde_plot_obs_est_inds","text":"","code":"hmde_plot_obs_est_inds(   estimate_list = NULL,   measurement_data = NULL,   ind_id_vec = NULL,   n_ind_to_plot = NULL,   xlab = \"Time\",   ylab = \"Y(t)\",   title = NULL )"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_obs_est_inds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot estimated and observed values over time for a chosen number of individuals based on posterior estimates. Structured to take in the measurement_data tibble constructed by the hmde_extract_estimates function. ‚Äî hmde_plot_obs_est_inds","text":"estimate_list list output hmde_extract_estimates measurement_data tibble estimated measurements ind_id_vec vector list ind_id values n_ind_to_plot integer giving number individuals plot specified xlab character string replacement x axis label ylab character string replacement y axis label title character string replacement plot title","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_obs_est_inds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot estimated and observed values over time for a chosen number of individuals based on posterior estimates. Structured to take in the measurement_data tibble constructed by the hmde_extract_estimates function. ‚Äî hmde_plot_obs_est_inds","text":"ggplot object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_plot_obs_est_inds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot estimated and observed values over time for a chosen number of individuals based on posterior estimates. Structured to take in the measurement_data tibble constructed by the hmde_extract_estimates function. ‚Äî hmde_plot_obs_est_inds","text":"","code":"# basic usage of hmde_plot_obs_est_inds hmde_plot_obs_est_inds(estimate_list = Tree_Size_Ests,                        n_ind_to_plot = 5)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run chosen pre-built model in Stan ‚Äî hmde_run","title":"Run chosen pre-built model in Stan ‚Äî hmde_run","text":"Run chosen pre-built model Stan","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run chosen pre-built model in Stan ‚Äî hmde_run","text":"","code":"hmde_run(model_template, ...)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run chosen pre-built model in Stan ‚Äî hmde_run","text":"model_template model template generated hmde_model updated hmde_assign_data ... additional arguments passed rstan::sampling","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run chosen pre-built model in Stan ‚Äî hmde_run","text":"Stanfit model output","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run chosen pre-built model in Stan ‚Äî hmde_run","text":"","code":"# basic usage of hmde_run hmde_model(\"constant_single_ind\") |>   hmde_assign_data(Trout_Size_Data)|>   hmde_run(chains = 1, iter = 1000,            verbose = FALSE, show_messages = FALSE) #>  #> SAMPLING FOR MODEL 'constant_single_ind' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.042 seconds (Warm-up) #> Chain 1:                0.032 seconds (Sampling) #> Chain 1:                0.074 seconds (Total) #> Chain 1:  #> Inference for Stan model: constant_single_ind. #> 1 chains, each with iter=1000; warmup=500; thin=1;  #> post-warmup draws per chain=500, total post-warmup draws=500. #>  #>                                           mean se_mean   sd    2.5%     25% #> ind_y_0                                  65.83    0.08 1.35   63.20   64.91 #> ind_beta                                  3.14    0.03 0.50    2.14    2.80 #> global_error_sigma                       11.19    0.04 0.74    9.85   10.69 #> y_hat[1]                                 65.83    0.08 1.35   63.20   64.91 #> y_hat[2]                                 71.83    0.03 0.92   69.98   71.25 #> y_hat[3]                                 78.44    0.06 1.39   75.73   77.53 #> y_hat[4]                                 84.77    0.12 2.26   80.46   83.23 #> y_hat[5]                                 65.83    0.08 1.35   63.20   64.91 #> y_hat[6]                                 71.78    0.03 0.92   69.93   71.20 #> y_hat[7]                                 78.18    0.06 1.36   75.53   77.31 #> y_hat[8]                                 84.54    0.11 2.23   80.28   83.03 #> y_hat[9]                                 65.83    0.08 1.35   63.20   64.91 #> y_hat[10]                                72.19    0.03 0.92   70.28   71.61 #> y_hat[11]                                79.11    0.06 1.48   76.21   78.12 #> y_hat[12]                                82.84    0.10 1.98   79.03   81.50 #> y_hat[13]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[14]                                68.32    0.06 1.09   66.20   67.62 #> y_hat[15]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[16]                                72.02    0.03 0.92   70.14   71.44 #> y_hat[17]                                78.04    0.06 1.35   75.42   77.18 #> y_hat[18]                                84.59    0.12 2.23   80.32   83.07 #> y_hat[19]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[20]                                68.50    0.06 1.08   66.41   67.81 #> y_hat[21]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[22]                                65.84    0.08 1.35   63.21   64.92 #> y_hat[23]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[24]                                71.34    0.04 0.93   69.50   70.74 #> y_hat[25]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[26]                                71.48    0.03 0.93   69.64   70.89 #> y_hat[27]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[28]                                71.76    0.03 0.92   69.91   71.18 #> y_hat[29]                                73.74    0.03 0.97   71.82   73.10 #> y_hat[30]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[31]                                68.16    0.06 1.11   66.02   67.43 #> y_hat[32]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[33]                                72.25    0.03 0.93   70.35   71.66 #> y_hat[34]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[35]                                72.20    0.03 0.93   70.30   71.62 #> y_hat[36]                                78.40    0.06 1.39   75.69   77.49 #> y_hat[37]                                84.13    0.11 2.17   79.97   82.67 #> y_hat[38]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[39]                                72.31    0.03 0.93   70.40   71.71 #> y_hat[40]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[41]                                72.57    0.03 0.93   70.69   71.97 #> y_hat[42]                                78.43    0.06 1.39   75.72   77.52 #> y_hat[43]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[44]                                71.76    0.03 0.92   69.91   71.17 #> y_hat[45]                                78.59    0.06 1.41   75.84   77.65 #> y_hat[46]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[47]                                72.12    0.03 0.92   70.22   71.54 #> y_hat[48]                                77.57    0.05 1.29   75.05   76.78 #> y_hat[49]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[50]                                72.39    0.03 0.93   70.49   71.79 #> y_hat[51]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[52]                                72.11    0.03 0.92   70.21   71.53 #> y_hat[53]                                78.15    0.06 1.36   75.50   77.28 #> y_hat[54]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[55]                                72.13    0.03 0.92   70.24   71.56 #> y_hat[56]                                72.15    0.03 0.92   70.25   71.58 #> y_hat[57]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[58]                                78.55    0.06 1.41   75.81   77.62 #> y_hat[59]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[60]                                72.25    0.03 0.93   70.35   71.66 #> y_hat[61]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[62]                                69.63    0.05 1.00   67.67   68.98 #> y_hat[63]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[64]                                72.03    0.03 0.92   70.15   71.45 #> y_hat[65]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[66]                                72.56    0.03 0.93   70.67   71.95 #> y_hat[67]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[68]                                71.64    0.03 0.93   69.80   71.04 #> y_hat[69]                                78.07    0.06 1.35   75.44   77.21 #> y_hat[70]                                81.28    0.08 1.76   77.84   80.12 #> y_hat[71]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[72]                                72.52    0.03 0.93   70.63   71.92 #> y_hat[73]                                74.75    0.03 1.03   72.68   74.08 #> y_hat[74]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[75]                                71.92    0.03 0.92   70.05   71.34 #> y_hat[76]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[77]                                68.66    0.05 1.06   66.60   67.95 #> y_hat[78]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[79]                                68.71    0.05 1.06   66.65   68.00 #> y_hat[80]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[81]                                68.49    0.06 1.08   66.40   67.80 #> y_hat[82]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[83]                                74.49    0.03 1.01   72.43   73.83 #> y_hat[84]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[85]                                68.58    0.05 1.07   66.50   67.87 #> y_hat[86]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[87]                                72.13    0.03 0.92   70.24   71.56 #> y_hat[88]                                78.33    0.06 1.38   75.64   77.43 #> y_hat[89]                                84.36    0.11 2.20   80.15   82.87 #> y_hat[90]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[91]                                71.07    0.04 0.93   69.20   70.45 #> y_hat[92]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[93]                                68.40    0.06 1.09   66.29   67.70 #> y_hat[94]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[95]                                76.18    0.04 1.15   74.10   75.41 #> y_hat[96]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[97]                                71.96    0.03 0.92   70.09   71.38 #> y_hat[98]                                75.95    0.04 1.13   73.92   75.20 #> y_hat[99]                                65.83    0.08 1.35   63.20   64.91 #> y_hat[100]                               71.95    0.03 0.92   70.07   71.37 #> y_hat[101]                               82.05    0.09 1.87   78.40   80.81 #> y_hat[102]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[103]                               71.35    0.04 0.93   69.51   70.75 #> y_hat[104]                               77.98    0.05 1.34   75.37   77.14 #> y_hat[105]                               81.65    0.09 1.81   78.11   80.44 #> y_hat[106]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[107]                               70.79    0.04 0.94   68.92   70.18 #> y_hat[108]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[109]                               71.53    0.03 0.93   69.69   70.93 #> y_hat[110]                               72.10    0.03 0.92   70.20   71.52 #> y_hat[111]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[112]                               72.71    0.03 0.93   70.85   72.08 #> y_hat[113]                               75.97    0.04 1.13   73.94   75.23 #> y_hat[114]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[115]                               72.17    0.03 0.92   70.27   71.60 #> y_hat[116]                               84.06    0.11 2.16   79.91   82.60 #> y_hat[117]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[118]                               66.55    0.07 1.27   64.04   65.66 #> y_hat[119]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[120]                               71.84    0.03 0.92   69.99   71.26 #> y_hat[121]                               78.34    0.06 1.38   75.65   77.43 #> y_hat[122]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[123]                               71.72    0.03 0.92   69.87   71.13 #> y_hat[124]                               77.72    0.05 1.31   75.17   76.91 #> y_hat[125]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[126]                               71.27    0.04 0.93   69.43   70.66 #> y_hat[127]                               77.82    0.05 1.32   75.25   77.00 #> y_hat[128]                               93.38    0.20 3.57   86.61   90.99 #> y_hat[129]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[130]                               71.87    0.03 0.92   70.01   71.28 #> y_hat[131]                               78.40    0.06 1.39   75.69   77.49 #> y_hat[132]                               87.78    0.15 2.71   82.57   85.97 #> y_hat[133]                               65.83    0.08 1.35   63.20   64.91 #> y_hat[134]                               78.40    0.06 1.39   75.69   77.49 #> y_hat[135]                               90.95    0.18 3.19   84.85   88.83 #> check_prior_pars_ind_beta[1]              0.00     NaN 0.00    0.00    0.00 #> check_prior_pars_ind_beta[2]              2.00     NaN 0.00    2.00    2.00 #> check_prior_pars_global_error_sigma[1]    0.00     NaN 0.00    0.00    0.00 #> check_prior_pars_global_error_sigma[2]    2.00     NaN 0.00    2.00    2.00 #> lp__                                   -391.19    0.08 1.26 -394.40 -391.73 #>                                            50%     75%   97.5% n_eff Rhat #> ind_y_0                                  65.87   66.69   68.54   286 1.00 #> ind_beta                                  3.11    3.48    4.13   266 1.00 #> global_error_sigma                       11.19   11.68   12.73   320 1.01 #> y_hat[1]                                 65.87   66.69   68.54   286 1.00 #> y_hat[2]                                 71.81   72.46   73.74   778 1.00 #> y_hat[3]                                 78.35   79.34   81.29   569 1.00 #> y_hat[4]                                 84.79   86.24   89.33   373 1.00 #> y_hat[5]                                 65.87   66.69   68.54   286 1.00 #> y_hat[6]                                 71.76   72.41   73.70   769 1.00 #> y_hat[7]                                 78.09   79.07   80.97   588 1.00 #> y_hat[8]                                 84.57   85.99   89.03   376 1.00 #> y_hat[9]                                 65.87   66.69   68.54   286 1.00 #> y_hat[10]                                72.16   72.81   74.07   833 1.00 #> y_hat[11]                                79.04   80.02   82.08   527 1.00 #> y_hat[12]                                82.86   84.09   86.83   403 1.00 #> y_hat[13]                                65.87   66.69   68.54   286 1.00 #> y_hat[14]                                68.33   69.01   70.44   365 1.00 #> y_hat[15]                                65.87   66.69   68.54   286 1.00 #> y_hat[16]                                72.00   72.65   73.92   808 1.00 #> y_hat[17]                                77.95   78.92   80.78   599 1.00 #> y_hat[18]                                84.62   86.04   89.09   375 1.00 #> y_hat[19]                                65.87   66.69   68.54   286 1.00 #> y_hat[20]                                68.50   69.17   70.60   377 1.00 #> y_hat[21]                                65.87   66.69   68.54   286 1.00 #> y_hat[22]                                65.88   66.70   68.54   287 1.00 #> y_hat[23]                                65.87   66.69   68.54   286 1.00 #> y_hat[24]                                71.31   71.94   73.29   699 1.00 #> y_hat[25]                                65.87   66.69   68.54   286 1.00 #> y_hat[26]                                71.46   72.08   73.43   721 1.00 #> y_hat[27]                                65.87   66.69   68.54   286 1.00 #> y_hat[28]                                71.75   72.39   73.68   767 1.00 #> y_hat[29]                                73.71   74.38   75.70   977 1.00 #> y_hat[30]                                65.87   66.69   68.54   286 1.00 #> y_hat[31]                                68.17   68.87   70.30   355 1.00 #> y_hat[32]                                65.87   66.69   68.54   286 1.00 #> y_hat[33]                                72.23   72.87   74.13   844 1.00 #> y_hat[34]                                65.87   66.69   68.54   286 1.00 #> y_hat[35]                                72.18   72.82   74.08   836 1.00 #> y_hat[36]                                78.31   79.30   81.24   572 1.00 #> y_hat[37]                                84.18   85.53   88.49   381 1.00 #> y_hat[38]                                65.87   66.69   68.54   286 1.00 #> y_hat[39]                                72.29   72.94   74.19   853 1.00 #> y_hat[40]                                65.87   66.69   68.54   286 1.00 #> y_hat[41]                                72.55   73.19   74.47   889 1.00 #> y_hat[42]                                78.35   79.33   81.28   570 1.00 #> y_hat[43]                                65.87   66.69   68.54   286 1.00 #> y_hat[44]                                71.74   72.38   73.67   765 1.00 #> y_hat[45]                                78.51   79.50   81.48   558 1.00 #> y_hat[46]                                65.87   66.69   68.54   286 1.00 #> y_hat[47]                                72.09   72.75   74.00   823 1.00 #> y_hat[48]                                77.51   78.42   80.17   640 1.00 #> y_hat[49]                                65.87   66.69   68.54   286 1.00 #> y_hat[50]                                72.37   73.02   74.28   864 1.00 #> y_hat[51]                                65.87   66.69   68.54   286 1.00 #> y_hat[52]                                72.09   72.74   74.00   821 1.00 #> y_hat[53]                                78.06   79.04   80.92   590 1.00 #> y_hat[54]                                65.87   66.69   68.54   286 1.00 #> y_hat[55]                                72.11   72.76   74.02   825 1.00 #> y_hat[56]                                72.13   72.78   74.03   828 1.00 #> y_hat[57]                                65.87   66.69   68.54   286 1.00 #> y_hat[58]                                78.46   79.45   81.43   561 1.00 #> y_hat[59]                                65.87   66.69   68.54   286 1.00 #> y_hat[60]                                72.23   72.87   74.13   844 1.00 #> y_hat[61]                                65.87   66.69   68.54   286 1.00 #> y_hat[62]                                69.62   70.29   71.63   485 1.00 #> y_hat[63]                                65.87   66.69   68.54   286 1.00 #> y_hat[64]                                72.01   72.66   73.93   809 1.00 #> y_hat[65]                                65.87   66.69   68.54   286 1.00 #> y_hat[66]                                72.53   73.17   74.45   887 1.00 #> y_hat[67]                                65.87   66.69   68.54   286 1.00 #> y_hat[68]                                71.63   72.25   73.57   747 1.00 #> y_hat[69]                                77.99   78.96   80.83   597 1.00 #> y_hat[70]                                81.32   82.40   84.80   439 1.00 #> y_hat[71]                                65.87   66.69   68.54   286 1.00 #> y_hat[72]                                72.50   73.14   74.42   882 1.00 #> y_hat[73]                                74.69   75.45   76.83   931 1.00 #> y_hat[74]                                65.87   66.69   68.54   286 1.00 #> y_hat[75]                                71.89   72.55   73.82   792 1.00 #> y_hat[76]                                65.87   66.69   68.54   286 1.00 #> y_hat[77]                                68.66   69.32   70.78   389 1.00 #> y_hat[78]                                65.87   66.69   68.54   286 1.00 #> y_hat[79]                                68.71   69.37   70.82   392 1.00 #> y_hat[80]                                65.87   66.69   68.54   286 1.00 #> y_hat[81]                                68.49   69.16   70.59   376 1.00 #> y_hat[82]                                65.87   66.69   68.54   286 1.00 #> y_hat[83]                                74.43   75.16   76.51   951 1.00 #> y_hat[84]                                65.87   66.69   68.54   286 1.00 #> y_hat[85]                                68.57   69.24   70.69   383 1.00 #> y_hat[86]                                65.87   66.69   68.54   286 1.00 #> y_hat[87]                                72.11   72.76   74.02   825 1.00 #> y_hat[88]                                78.24   79.22   81.15   577 1.00 #> y_hat[89]                                84.40   85.78   88.78   378 1.00 #> y_hat[90]                                65.87   66.69   68.54   286 1.00 #> y_hat[91]                                71.04   71.68   73.05   659 1.00 #> y_hat[92]                                65.87   66.69   68.54   286 1.00 #> y_hat[93]                                68.41   69.08   70.51   370 1.00 #> y_hat[94]                                65.87   66.69   68.54   286 1.00 #> y_hat[95]                                76.12   76.93   78.48   785 1.00 #> y_hat[96]                                65.87   66.69   68.54   286 1.00 #> y_hat[97]                                71.93   72.60   73.86   798 1.00 #> y_hat[98]                                75.87   76.69   78.24   809 1.00 #> y_hat[99]                                65.87   66.69   68.54   286 1.00 #> y_hat[100]                               71.92   72.58   73.84   796 1.00 #> y_hat[101]                               82.09   83.24   85.79   419 1.00 #> y_hat[102]                               65.87   66.69   68.54   286 1.00 #> y_hat[103]                               71.33   71.95   73.31   701 1.00 #> y_hat[104]                               77.90   78.87   80.72   604 1.00 #> y_hat[105]                               81.70   82.80   85.27   429 1.00 #> y_hat[106]                               65.87   66.69   68.54   286 1.00 #> y_hat[107]                               70.77   71.40   72.78   620 1.00 #> y_hat[108]                               65.87   66.69   68.54   286 1.00 #> y_hat[109]                               71.51   72.14   73.47   730 1.00 #> y_hat[110]                               72.08   72.73   73.99   820 1.00 #> y_hat[111]                               65.87   66.69   68.54   286 1.00 #> y_hat[112]                               72.68   73.32   74.61   907 1.00 #> y_hat[113]                               75.90   76.71   78.26   806 1.00 #> y_hat[114]                               65.87   66.69   68.54   286 1.00 #> y_hat[115]                               72.15   72.80   74.05   831 1.00 #> y_hat[116]                               84.10   85.45   88.39   382 1.00 #> y_hat[117]                               65.87   66.69   68.54   286 1.00 #> y_hat[118]                               66.58   67.37   69.03   298 1.00 #> y_hat[119]                               65.87   66.69   68.54   286 1.00 #> y_hat[120]                               71.81   72.47   73.75   779 1.00 #> y_hat[121]                               78.25   79.23   81.16   576 1.00 #> y_hat[122]                               65.87   66.69   68.54   286 1.00 #> y_hat[123]                               71.70   72.35   73.64   760 1.00 #> y_hat[124]                               77.64   78.59   80.36   626 1.00 #> y_hat[125]                               65.87   66.69   68.54   286 1.00 #> y_hat[126]                               71.25   71.87   73.23   688 1.00 #> y_hat[127]                               77.75   78.70   80.50   617 1.00 #> y_hat[128]                               93.35   95.72  100.24   317 1.00 #> y_hat[129]                               65.87   66.69   68.54   286 1.00 #> y_hat[130]                               71.84   72.50   73.77   783 1.00 #> y_hat[131]                               78.31   79.30   81.24   572 1.00 #> y_hat[132]                               87.75   89.55   93.22   344 1.00 #> y_hat[133]                               65.87   66.69   68.54   286 1.00 #> y_hat[134]                               78.31   79.30   81.24   572 1.00 #> y_hat[135]                               90.92   93.04   97.17   326 1.00 #> check_prior_pars_ind_beta[1]              0.00    0.00    0.00   NaN  NaN #> check_prior_pars_ind_beta[2]              2.00    2.00    2.00   NaN  NaN #> check_prior_pars_global_error_sigma[1]    0.00    0.00    0.00   NaN  NaN #> check_prior_pars_global_error_sigma[2]    2.00    2.00    2.00   NaN  NaN #> lp__                                   -390.86 -390.25 -389.74   263 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Dec 24 00:25:27 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_vb_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential equation for von Bertalanffy growth single and multi- individual models ‚Äî hmde_vb_de","title":"Differential equation for von Bertalanffy growth single and multi- individual models ‚Äî hmde_vb_de","text":"Differential equation von Bertalanffy growth single multi- individual models","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_vb_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential equation for von Bertalanffy growth single and multi- individual models ‚Äî hmde_vb_de","text":"","code":"hmde_vb_de(y = NULL, pars = NULL)"},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_vb_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential equation for von Bertalanffy growth single and multi- individual models ‚Äî hmde_vb_de","text":"y input real pars list parameters Y_max, growth_rate","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/hmde_vb_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential equation for von Bertalanffy growth single and multi- individual models ‚Äî hmde_vb_de","text":"value differential equation y","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/plot.hmde_model_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot function for hmde_model_template object ‚Äî plot.hmde_model_template","title":"Plot function for hmde_model_template object ‚Äî plot.hmde_model_template","text":"Plot function hmde_model_template object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/plot.hmde_model_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot function for hmde_model_template object ‚Äî plot.hmde_model_template","text":"","code":"# S3 method for class 'hmde_model_template' plot(x, ...)"},{"path":"https://traitecoevo.github.io/hmde/reference/plot.hmde_model_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot function for hmde_model_template object ‚Äî plot.hmde_model_template","text":"x hmde_model_template output hmde_model ... Additional argument space conform S3 template.","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/plot.hmde_model_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot function for hmde_model_template object ‚Äî plot.hmde_model_template","text":"","code":"# basic usage of plot hmde_model(\"constant_single_ind\") |> plot()"},{"path":"https://traitecoevo.github.io/hmde/reference/print.hmde_model_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for hmde_model_template object ‚Äî print.hmde_model_template","title":"Print function for hmde_model_template object ‚Äî print.hmde_model_template","text":"Print function hmde_model_template object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/print.hmde_model_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for hmde_model_template object ‚Äî print.hmde_model_template","text":"","code":"# S3 method for class 'hmde_model_template' print(x, ...)"},{"path":"https://traitecoevo.github.io/hmde/reference/print.hmde_model_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for hmde_model_template object ‚Äî print.hmde_model_template","text":"x hmde_model_template output hmde_model ... parameters used print","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/print.hmde_model_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for hmde_model_template object ‚Äî print.hmde_model_template","text":"","code":"# basic usage of print hmde_model(\"constant_single_ind\") |> print() #> [1] \"Model: constant_single_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $prior_pars_ind_beta #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_single_ind\" #>"},{"path":"https://traitecoevo.github.io/hmde/reference/summary.hmde_model_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for hmde_model_template object ‚Äî summary.hmde_model_template","title":"Summary function for hmde_model_template object ‚Äî summary.hmde_model_template","text":"Summary function hmde_model_template object","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/summary.hmde_model_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for hmde_model_template object ‚Äî summary.hmde_model_template","text":"","code":"# S3 method for class 'hmde_model_template' summary(object, ...)"},{"path":"https://traitecoevo.github.io/hmde/reference/summary.hmde_model_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for hmde_model_template object ‚Äî summary.hmde_model_template","text":"object hmde_model_template output hmde_model ... parameters used print","code":""},{"path":"https://traitecoevo.github.io/hmde/reference/summary.hmde_model_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for hmde_model_template object ‚Äî summary.hmde_model_template","text":"","code":"# basic usage of summary hmde_model(\"constant_single_ind\") |> summary() #> [1] \"Model: constant_single_ind\" #> [1] \"Input data template:\" #> $n_obs #> NULL #>  #> $y_obs #> NULL #>  #> $obs_index #> NULL #>  #> $time #> NULL #>  #> $prior_pars_ind_beta #> [1] 0 2 #>  #> $prior_pars_global_error_sigma #> [1] 0 2 #>  #> $model #> [1] \"constant_single_ind\" #>"},{"path":"https://traitecoevo.github.io/hmde/news/index.html","id":"hmde-131","dir":"Changelog","previous_headings":"","what":"hmde 1.3.1","title":"hmde 1.3.1","text":"CRAN release: 2025-12-23 Finalised added vignettes package.","code":""}]
